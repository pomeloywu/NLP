{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6417fdbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from dataclasses import dataclass\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae260d02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>summary</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Drowned Wednesday</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>Drowned Wednesday is the first Trustee among ...</td>\n",
       "      <td>drown wednesday first trustee among morrow day...</td>\n",
       "      <td>drown wednesday</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Lost Hero</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>As the book opens, Jason awakens on a school ...</td>\n",
       "      <td>book open jason awakens school bus unable reme...</td>\n",
       "      <td>lose hero</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thendara House</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>The novel concerns the dwelling of the Darkov...</td>\n",
       "      <td>novel concern dwell darkovan order renunciates...</td>\n",
       "      <td>thendara house</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Thief</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>Gen is released from prison by the magus, the...</td>\n",
       "      <td>gen release prison magus king scholar magus fi...</td>\n",
       "      <td>thief</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Sweet Far Thing</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>The prologue begins with two men who are sear...</td>\n",
       "      <td>prologue begin two men search river london thr...</td>\n",
       "      <td>sweet far thing</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>The Time Traveler's Wife</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>This is the extraordinary love story of Clare ...</td>\n",
       "      <td>extraordinary love story clare henry meet clar...</td>\n",
       "      <td>time traveler wife</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>Fantastic Beasts and Where to Find Them: The O...</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>J.K. Rowling's screenwriting debut is captured...</td>\n",
       "      <td>j k rowling screenwriting debut capture exciti...</td>\n",
       "      <td>fantastic beast find original screenplay</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>Charlie and the Chocolate Factory</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>Charlie Bucket's wonderful adventure begins wh...</td>\n",
       "      <td>charlie bucket wonderful adventure begin find ...</td>\n",
       "      <td>charlie chocolate factory</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>Frostbite</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>Rose loves Dimitri, Dimitri might love Tasha, ...</td>\n",
       "      <td>rise love dimitri dimitri might love tasha mas...</td>\n",
       "      <td>frostbite</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>Radiance</td>\n",
       "      <td>fantasy</td>\n",
       "      <td>The Prince of no value\\nBrishen Khaskem, princ...</td>\n",
       "      <td>prince value brishen khaskem prince kai live c...</td>\n",
       "      <td>radiance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2991 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  title    genre  \\\n",
       "0                                     Drowned Wednesday  fantasy   \n",
       "1                                         The Lost Hero  fantasy   \n",
       "2                                        Thendara House  fantasy   \n",
       "3                                             The Thief  fantasy   \n",
       "4                                   The Sweet Far Thing  fantasy   \n",
       "...                                                 ...      ...   \n",
       "2995                           The Time Traveler's Wife  fantasy   \n",
       "2996  Fantastic Beasts and Where to Find Them: The O...  fantasy   \n",
       "2997                  Charlie and the Chocolate Factory  fantasy   \n",
       "2998                                          Frostbite  fantasy   \n",
       "2999                                           Radiance  fantasy   \n",
       "\n",
       "                                                summary  \\\n",
       "0      Drowned Wednesday is the first Trustee among ...   \n",
       "1      As the book opens, Jason awakens on a school ...   \n",
       "2      The novel concerns the dwelling of the Darkov...   \n",
       "3      Gen is released from prison by the magus, the...   \n",
       "4      The prologue begins with two men who are sear...   \n",
       "...                                                 ...   \n",
       "2995  This is the extraordinary love story of Clare ...   \n",
       "2996  J.K. Rowling's screenwriting debut is captured...   \n",
       "2997  Charlie Bucket's wonderful adventure begins wh...   \n",
       "2998  Rose loves Dimitri, Dimitri might love Tasha, ...   \n",
       "2999  The Prince of no value\\nBrishen Khaskem, princ...   \n",
       "\n",
       "                                             clean_text  \\\n",
       "0     drown wednesday first trustee among morrow day...   \n",
       "1     book open jason awakens school bus unable reme...   \n",
       "2     novel concern dwell darkovan order renunciates...   \n",
       "3     gen release prison magus king scholar magus fi...   \n",
       "4     prologue begin two men search river london thr...   \n",
       "...                                                 ...   \n",
       "2995  extraordinary love story clare henry meet clar...   \n",
       "2996  j k rowling screenwriting debut capture exciti...   \n",
       "2997  charlie bucket wonderful adventure begin find ...   \n",
       "2998  rise love dimitri dimitri might love tasha mas...   \n",
       "2999  prince value brishen khaskem prince kai live c...   \n",
       "\n",
       "                                   clean_title  class  \n",
       "0                              drown wednesday      1  \n",
       "1                                    lose hero      1  \n",
       "2                               thendara house      1  \n",
       "3                                        thief      1  \n",
       "4                              sweet far thing      1  \n",
       "...                                        ...    ...  \n",
       "2995                        time traveler wife      1  \n",
       "2996  fantastic beast find original screenplay      1  \n",
       "2997                 charlie chocolate factory      1  \n",
       "2998                                 frostbite      1  \n",
       "2999                                  radiance      1  \n",
       "\n",
       "[2991 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_data = pd.read_csv('./Data/data_processed.csv').dropna()\n",
    "le = preprocessing.LabelEncoder()\n",
    "df_data['class'] = le.fit_transform(df_data.genre)\n",
    "df_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "548aa9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self, text, Y, transform = None):\n",
    "        self.text = text\n",
    "        self.Y = Y\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.Y)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.text[idx], self.Y[idx]\n",
    "    \n",
    "\n",
    "def str2idx(df, word2index, cut_length):\n",
    "    idx_seq_li = []\n",
    "    for i in range(len(df)):\n",
    "        idx_li = []\n",
    "        for w in word_tokenize(df.clean_text.iloc[i]):\n",
    "            if word2index.get(w):\n",
    "                idx = word2index[w]\n",
    "            else:\n",
    "                idx = word2index['UNK']\n",
    "            idx_li.append(idx)\n",
    "\n",
    "        if len(idx_li) >= cut_length:\n",
    "            idx_li = idx_li[:cut_length]\n",
    "        else:\n",
    "            for i in range(cut_length - len(idx_li)):\n",
    "                idx_li.append(0)\n",
    "        idx_seq_li.append(idx_li)\n",
    "    return np.array(idx_seq_li)\n",
    "\n",
    "\n",
    "def generate_data_loader(df_data, batch_size, cut_length):\n",
    "    \n",
    "    X = np.arange(len(df_data))\n",
    "    y = df_data['class']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.1, stratify=y, random_state=23)\n",
    "\n",
    "    data_train = df_data.iloc[X_train]\n",
    "    data_test = df_data.iloc[X_test] \n",
    "\n",
    "    # word2index\n",
    "    all_words = [i for w in list(data_train.clean_text) for i in word_tokenize(w)]\n",
    "    unique_words = list(set(all_words))\n",
    "    word2index = {w:i+1 for i,w in enumerate(unique_words)}\n",
    "    word2index['PAD'] = 0\n",
    "    word2index['UNK'] = len(word2index)\n",
    "\n",
    "    train_arr = str2idx(data_train, word2index, cut_length)\n",
    "    test_arr = str2idx(data_test, word2index, cut_length)\n",
    "\n",
    "    train_data = TextDataset(torch.from_numpy(train_arr).long(), \n",
    "                         torch.from_numpy(y_train.to_numpy()).long())\n",
    "\n",
    "    test_data = TextDataset(torch.from_numpy(test_arr).long(),\n",
    "                        torch.from_numpy(y_test.to_numpy()).long())\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "    train_data, batch_size=batch_size, shuffle=False)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "    test_data, batch_size=batch_size, shuffle=False)\n",
    "    \n",
    "    return data_train, data_test, train_loader, test_loader, word2index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e775bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextCNN(nn.ModuleList):\n",
    "\n",
    "    def __init__(self, params):\n",
    "        super(TextCNN, self).__init__()\n",
    "\n",
    "        # Parameters regarding text preprocessing\n",
    "        self.seq_len = params.seq_len\n",
    "        self.num_words = params.num_words\n",
    "        self.embedding_size = params.embedding_size\n",
    "\n",
    "        # Dropout definition\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "        # CNN parameters definition\n",
    "        # Kernel sizes\n",
    "        self.kernel_1 = 2\n",
    "        self.kernel_2 = 3\n",
    "        self.kernel_3 = 4\n",
    "        self.kernel_4 = 5\n",
    "\n",
    "        # Output size for each convolution\n",
    "        self.out_size = params.out_size\n",
    "        \n",
    "        # Number of strides for each convolution\n",
    "        self.stride = params.stride\n",
    "        \n",
    "        # Dense layers\n",
    "        self.dense_out = params.dense_out\n",
    "        self.class_num = params.class_num\n",
    "\n",
    "        # Embedding layer definition\n",
    "        self.embedding = nn.Embedding(self.num_words, self.embedding_size, padding_idx=0)\n",
    "\n",
    "        # Convolution layers definition\n",
    "        self.conv_1 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_1, self.stride)\n",
    "        self.conv_2 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_2, self.stride)\n",
    "        self.conv_3 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_3, self.stride)\n",
    "        self.conv_4 = nn.Conv1d(self.seq_len, self.out_size, self.kernel_4, self.stride)\n",
    "\n",
    "        # Max pooling layers definition\n",
    "        self.pool_1 = nn.MaxPool1d(self.kernel_1, self.stride)\n",
    "        self.pool_2 = nn.MaxPool1d(self.kernel_2, self.stride)\n",
    "        self.pool_3 = nn.MaxPool1d(self.kernel_3, self.stride)\n",
    "        self.pool_4 = nn.MaxPool1d(self.kernel_4, self.stride)\n",
    "\n",
    "        # Fully connected layer definition\n",
    "        self.fc1 = nn.Linear(self.in_features_fc(), self.dense_out)\n",
    "        self.fc2 = nn.Linear(self.dense_out, self.class_num)\n",
    "        \n",
    "        \n",
    "    def in_features_fc(self):\n",
    "        '''Calculates the number of output features after Convolution + Max pooling\n",
    "\n",
    "        Convolved_Features = ((embedding_size + (2 * padding) - dilation * (kernel - 1) - 1) / stride) + 1\n",
    "        Pooled_Features = ((embedding_size + (2 * padding) - dilation * (kernel - 1) - 1) / stride) + 1\n",
    "\n",
    "        source: https://pytorch.org/docs/stable/generated/torch.nn.Conv1d.html\n",
    "        '''\n",
    "        # Calcualte size of convolved/pooled features for convolution_1/max_pooling_1 features\n",
    "        out_conv_1 = ((self.embedding_size - 1 * (self.kernel_1 - 1) - 1) / self.stride) + 1\n",
    "        out_conv_1 = math.floor(out_conv_1)\n",
    "        out_pool_1 = ((out_conv_1 - 1 * (self.kernel_1 - 1) - 1) / self.stride) + 1\n",
    "        out_pool_1 = math.floor(out_pool_1)\n",
    "\n",
    "        # Calcualte size of convolved/pooled features for convolution_2/max_pooling_2 features\n",
    "        out_conv_2 = ((self.embedding_size - 1 * (self.kernel_2 - 1) - 1) / self.stride) + 1\n",
    "        out_conv_2 = math.floor(out_conv_2)\n",
    "        out_pool_2 = ((out_conv_2 - 1 * (self.kernel_2 - 1) - 1) / self.stride) + 1\n",
    "        out_pool_2 = math.floor(out_pool_2)\n",
    "\n",
    "        # Calcualte size of convolved/pooled features for convolution_3/max_pooling_3 features\n",
    "        out_conv_3 = ((self.embedding_size - 1 * (self.kernel_3 - 1) - 1) / self.stride) + 1\n",
    "        out_conv_3 = math.floor(out_conv_3)\n",
    "        out_pool_3 = ((out_conv_3 - 1 * (self.kernel_3 - 1) - 1) / self.stride) + 1\n",
    "        out_pool_3 = math.floor(out_pool_3)\n",
    "\n",
    "        # Calcualte size of convolved/pooled features for convolution_4/max_pooling_4 features\n",
    "        out_conv_4 = ((self.embedding_size - 1 * (self.kernel_4 - 1) - 1) / self.stride) + 1\n",
    "        out_conv_4 = math.floor(out_conv_4)\n",
    "        out_pool_4 = ((out_conv_4 - 1 * (self.kernel_4 - 1) - 1) / self.stride) + 1\n",
    "        out_pool_4 = math.floor(out_pool_4)\n",
    "\n",
    "        # Returns \"flattened\" vector (input for fully connected layer)\n",
    "        return (out_pool_1 + out_pool_2 + out_pool_3 + out_pool_4) * self.out_size\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "\n",
    "        # Sequence of tokes is filterd through an embedding layer\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # Convolution layer 1 is applied\n",
    "        x1 = self.conv_1(x)\n",
    "        x1 = torch.relu(x1)\n",
    "        x1 = self.pool_1(x1)\n",
    "\n",
    "        # Convolution layer 2 is applied\n",
    "        x2 = self.conv_2(x)\n",
    "        x2 = torch.relu((x2))\n",
    "        x2 = self.pool_2(x2)\n",
    "\n",
    "        # Convolution layer 3 is applied\n",
    "        x3 = self.conv_3(x)\n",
    "        x3 = torch.relu(x3)\n",
    "        x3 = self.pool_3(x3)\n",
    "\n",
    "        # Convolution layer 4 is applied\n",
    "        x4 = self.conv_4(x)\n",
    "        x4 = torch.relu(x4)\n",
    "        x4 = self.pool_4(x4)\n",
    "\n",
    "        # The output of each convolutional layer is concatenated into a unique vector\n",
    "        union = torch.cat((x1, x2, x3, x4), 2)\n",
    "        union = union.reshape(union.size(0), -1)\n",
    "\n",
    "        # The \"flattened\" vector is passed through a fully connected layer\n",
    "        out = self.fc1(union)\n",
    "        # Dropout is applied\n",
    "        out = self.dropout(out)\n",
    "        out = self.fc2(out)\n",
    "        # Activation function is applied\n",
    "        out = F.log_softmax(out, dim=1)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2284b3ff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextCNN(\n",
      "  (dropout): Dropout(p=0.5, inplace=False)\n",
      "  (embedding): Embedding(37949, 100, padding_idx=0)\n",
      "  (conv_1): Conv1d(500, 64, kernel_size=(2,), stride=(2,))\n",
      "  (conv_2): Conv1d(500, 64, kernel_size=(3,), stride=(2,))\n",
      "  (conv_3): Conv1d(500, 64, kernel_size=(4,), stride=(2,))\n",
      "  (conv_4): Conv1d(500, 64, kernel_size=(5,), stride=(2,))\n",
      "  (pool_1): MaxPool1d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool_2): MaxPool1d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool_3): MaxPool1d(kernel_size=4, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (pool_4): MaxPool1d(kernel_size=5, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (fc1): Linear(in_features=6016, out_features=128, bias=True)\n",
      "  (fc2): Linear(in_features=128, out_features=6, bias=True)\n",
      ")\n",
      "\n",
      " EPOCH 1/1000 \t train loss 22.24051909013228 \t val loss 21.40981928507487\n",
      "train accuracy 0.16610925306577481 \t val accuracy 0.16666666666666666\n",
      "\n",
      " EPOCH 2/1000 \t train loss 20.995990493080832 \t val loss 20.96809196472168\n",
      "train accuracy 0.2623560014864363 \t val accuracy 0.22333333333333333\n",
      "\n",
      " EPOCH 3/1000 \t train loss 20.327561551874336 \t val loss 20.762365341186523\n",
      "train accuracy 0.5072463768115942 \t val accuracy 0.24\n",
      "\n",
      " EPOCH 4/1000 \t train loss 19.74622813138095 \t val loss 20.465227762858074\n",
      "train accuracy 0.7421033073206986 \t val accuracy 0.2\n",
      "\n",
      " EPOCH 5/1000 \t train loss 19.195657470009543 \t val loss 20.47196896870931\n",
      "train accuracy 0.865849126718692 \t val accuracy 0.18333333333333332\n",
      "\n",
      " EPOCH 6/1000 \t train loss 18.72680594704368 \t val loss 20.02779769897461\n",
      "train accuracy 0.8959494611668525 \t val accuracy 0.23333333333333334\n",
      "\n",
      " EPOCH 7/1000 \t train loss 18.300502517006613 \t val loss 20.70632489522298\n",
      "train accuracy 0.9546636937941286 \t val accuracy 0.18\n",
      "\n",
      " EPOCH 8/1000 \t train loss 17.997879028320312 \t val loss 20.7298641204834\n",
      "train accuracy 0.9450018580453363 \t val accuracy 0.19333333333333333\n",
      "\n",
      " EPOCH 9/1000 \t train loss 17.9110370982777 \t val loss 19.650462468465168\n",
      "train accuracy 0.8777406168710516 \t val accuracy 0.2833333333333333\n",
      "\n",
      " EPOCH 10/1000 \t train loss 17.904339270158246 \t val loss 21.910219192504883\n",
      "train accuracy 0.7974730583426236 \t val accuracy 0.19\n",
      "\n",
      " EPOCH 11/1000 \t train loss 17.45360530506481 \t val loss 19.77830696105957\n",
      "train accuracy 0.885916016350799 \t val accuracy 0.2733333333333333\n",
      "\n",
      " EPOCH 12/1000 \t train loss 17.040575981140137 \t val loss 19.776127497355144\n",
      "train accuracy 0.9736157562244518 \t val accuracy 0.24\n",
      "\n",
      " EPOCH 13/1000 \t train loss 16.790155844254926 \t val loss 19.051209767659504\n",
      "train accuracy 0.9829059829059829 \t val accuracy 0.26\n",
      "\n",
      " EPOCH 14/1000 \t train loss 16.54822757027366 \t val loss 18.994564692179363\n",
      "train accuracy 0.9884801189149015 \t val accuracy 0.2733333333333333\n",
      "\n",
      " EPOCH 15/1000 \t train loss 16.33250297199596 \t val loss 19.088233311971027\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.2833333333333333\n",
      "\n",
      " EPOCH 16/1000 \t train loss 16.112465945157137 \t val loss 19.052385330200195\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.2866666666666667\n",
      "\n",
      " EPOCH 17/1000 \t train loss 15.894794767553156 \t val loss 18.970670700073242\n",
      "train accuracy 0.9881085098476403 \t val accuracy 0.26666666666666666\n",
      "\n",
      " EPOCH 18/1000 \t train loss 15.683369679884477 \t val loss 18.06884829203288\n",
      "train accuracy 0.9884801189149015 \t val accuracy 0.31\n",
      "\n",
      " EPOCH 19/1000 \t train loss 15.480694337324662 \t val loss 18.001237869262695\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.26666666666666666\n",
      "\n",
      " EPOCH 20/1000 \t train loss 15.234123533422297 \t val loss 17.488854726155598\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.31333333333333335\n",
      "\n",
      " EPOCH 21/1000 \t train loss 15.027674935080789 \t val loss 17.120179494222004\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.30666666666666664\n",
      "\n",
      " EPOCH 22/1000 \t train loss 14.815423228523947 \t val loss 16.866154352823894\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.36333333333333334\n",
      "\n",
      " EPOCH 23/1000 \t train loss 14.590357130224055 \t val loss 16.60093943277995\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.35\n",
      "\n",
      " EPOCH 24/1000 \t train loss 14.380817500027744 \t val loss 16.52671941121419\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.29\n",
      "\n",
      " EPOCH 25/1000 \t train loss 14.159606023268266 \t val loss 16.20843442281087\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.35\n",
      "\n",
      " EPOCH 26/1000 \t train loss 13.950545701113613 \t val loss 15.987308820088705\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.36333333333333334\n",
      "\n",
      " EPOCH 27/1000 \t train loss 13.74495705691251 \t val loss 15.69456704457601\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.34\n",
      "\n",
      " EPOCH 28/1000 \t train loss 13.518218170512807 \t val loss 15.539436976114908\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.31666666666666665\n",
      "\n",
      " EPOCH 29/1000 \t train loss 13.313098127191717 \t val loss 15.299006144205729\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.3433333333333333\n",
      "\n",
      " EPOCH 30/1000 \t train loss 13.099945241754705 \t val loss 15.203275680541992\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.33\n",
      "\n",
      " EPOCH 31/1000 \t train loss 12.882665937597102 \t val loss 14.876579920450846\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.3466666666666667\n",
      "\n",
      " EPOCH 32/1000 \t train loss 12.679274515672164 \t val loss 14.74342409769694\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.31666666666666665\n",
      "\n",
      " EPOCH 33/1000 \t train loss 12.477890751578592 \t val loss 14.443080266316732\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.3466666666666667\n",
      "\n",
      " EPOCH 34/1000 \t train loss 12.264570149508389 \t val loss 14.391751607259115\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.30666666666666664\n",
      "\n",
      " EPOCH 35/1000 \t train loss 12.062588344920766 \t val loss 14.151235898335775\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.2966666666666667\n",
      "\n",
      " EPOCH 36/1000 \t train loss 11.86344727602872 \t val loss 14.023936907450357\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.31666666666666665\n",
      "\n",
      " EPOCH 37/1000 \t train loss 11.651625156402588 \t val loss 13.58650271097819\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.33\n",
      "\n",
      " EPOCH 38/1000 \t train loss 11.455779812552713 \t val loss 13.541942596435547\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.31\n",
      "\n",
      " EPOCH 39/1000 \t train loss 11.251124468716709 \t val loss 13.354951540629068\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.31666666666666665\n",
      "\n",
      " EPOCH 40/1000 \t train loss 11.056434804742986 \t val loss 12.905817349751791\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.35333333333333333\n",
      "\n",
      " EPOCH 41/1000 \t train loss 10.858512791720303 \t val loss 12.642984708150228\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.35\n",
      "\n",
      " EPOCH 42/1000 \t train loss 10.661701809276234 \t val loss 12.48286247253418\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.36\n",
      "\n",
      " EPOCH 43/1000 \t train loss 10.479193644090133 \t val loss 12.272592544555664\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.34\n",
      "\n",
      " EPOCH 44/1000 \t train loss 10.277990254488858 \t val loss 12.089612325032553\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.36333333333333334\n",
      "\n",
      " EPOCH 45/1000 \t train loss 10.0896352854642 \t val loss 11.821290016174316\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.3566666666666667\n",
      "\n",
      " EPOCH 46/1000 \t train loss 9.903203574093906 \t val loss 11.622213363647461\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.36\n",
      "\n",
      " EPOCH 47/1000 \t train loss 9.71006068316373 \t val loss 11.455663681030273\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.36333333333333334\n",
      "\n",
      " EPOCH 48/1000 \t train loss 9.525639924136074 \t val loss 11.269943555196127\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.37666666666666665\n",
      "\n",
      " EPOCH 49/1000 \t train loss 9.339515512639826 \t val loss 11.106837272644043\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.37666666666666665\n",
      "\n",
      " EPOCH 50/1000 \t train loss 9.154019182378596 \t val loss 10.989721298217773\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.35\n",
      "\n",
      " EPOCH 51/1000 \t train loss 8.972540378570557 \t val loss 10.779437700907389\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.3933333333333333\n",
      "\n",
      " EPOCH 52/1000 \t train loss 8.79460183056918 \t val loss 10.705262502034506\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.3566666666666667\n",
      "\n",
      " EPOCH 53/1000 \t train loss 8.62105690349232 \t val loss 10.459673881530762\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.37\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 54/1000 \t train loss 8.449050079692494 \t val loss 10.235044161478678\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.38666666666666666\n",
      "\n",
      " EPOCH 55/1000 \t train loss 8.25872312892567 \t val loss 10.275072733561197\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.35333333333333333\n",
      "\n",
      " EPOCH 56/1000 \t train loss 8.104702711105347 \t val loss 10.055598894755045\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.34\n",
      "\n",
      " EPOCH 57/1000 \t train loss 7.918220736763694 \t val loss 9.874881426493326\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.36\n",
      "\n",
      " EPOCH 58/1000 \t train loss 7.760289322246205 \t val loss 9.791688601175943\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.36333333333333334\n",
      "\n",
      " EPOCH 59/1000 \t train loss 7.5790700695731426 \t val loss 9.540024439493815\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.36\n",
      "\n",
      " EPOCH 60/1000 \t train loss 7.426887273788452 \t val loss 9.59855842590332\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.3433333333333333\n",
      "\n",
      " EPOCH 61/1000 \t train loss 7.2550600658763535 \t val loss 9.141948699951172\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.36\n",
      "\n",
      " EPOCH 62/1000 \t train loss 7.09424224766818 \t val loss 9.234524726867676\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.35\n",
      "\n",
      " EPOCH 63/1000 \t train loss 6.943688067522916 \t val loss 8.95824114481608\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.35\n",
      "\n",
      " EPOCH 64/1000 \t train loss 6.785127314654264 \t val loss 9.045105616251627\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.3333333333333333\n",
      "\n",
      " EPOCH 65/1000 \t train loss 6.6320742260326035 \t val loss 8.668951670328775\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.37\n",
      "\n",
      " EPOCH 66/1000 \t train loss 6.479660684412176 \t val loss 8.816792805989584\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.3433333333333333\n",
      "\n",
      " EPOCH 67/1000 \t train loss 6.327624104239724 \t val loss 8.659922281901041\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.3433333333333333\n",
      "\n",
      " EPOCH 68/1000 \t train loss 6.194572622125799 \t val loss 8.58099333445231\n",
      "train accuracy 0.9884801189149015 \t val accuracy 0.3566666666666667\n",
      "\n",
      " EPOCH 69/1000 \t train loss 6.0421155799518935 \t val loss 8.5338716506958\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.33666666666666667\n",
      "\n",
      " EPOCH 70/1000 \t train loss 5.900524551218206 \t val loss 8.512238184611002\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.3566666666666667\n",
      "\n",
      " EPOCH 71/1000 \t train loss 5.771931388161399 \t val loss 8.982455571492514\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.31\n",
      "\n",
      " EPOCH 72/1000 \t train loss 5.652592052112926 \t val loss 8.606316884358725\n",
      "train accuracy 0.987736900780379 \t val accuracy 0.33\n",
      "\n",
      " EPOCH 73/1000 \t train loss 5.5741284543817695 \t val loss 8.764039357503256\n",
      "train accuracy 0.9791898922333705 \t val accuracy 0.34\n",
      "\n",
      " EPOCH 74/1000 \t train loss 5.510533918033946 \t val loss 8.925262133280436\n",
      "train accuracy 0.9639539204756596 \t val accuracy 0.3566666666666667\n",
      "\n",
      " EPOCH 75/1000 \t train loss 5.545182249762795 \t val loss 12.828921953837076\n",
      "train accuracy 0.9483463396506875 \t val accuracy 0.23333333333333334\n",
      "\n",
      " EPOCH 76/1000 \t train loss 7.5875137935985215 \t val loss 11.65789826711019\n",
      "train accuracy 0.6975102192493496 \t val accuracy 0.37666666666666665\n",
      "\n",
      " EPOCH 77/1000 \t train loss 6.613570300015536 \t val loss 11.857064882914225\n",
      "train accuracy 0.8372352285395763 \t val accuracy 0.43666666666666665\n",
      "\n",
      " EPOCH 78/1000 \t train loss 5.818388895554976 \t val loss 9.328195571899414\n",
      "train accuracy 0.919732441471572 \t val accuracy 0.4633333333333333\n",
      "\n",
      " EPOCH 79/1000 \t train loss 5.4424521056088535 \t val loss 9.683624267578125\n",
      "train accuracy 0.9725009290226682 \t val accuracy 0.44333333333333336\n",
      "\n",
      " EPOCH 80/1000 \t train loss 5.288203044371172 \t val loss 9.472379048665365\n",
      "train accuracy 0.9855072463768116 \t val accuracy 0.44333333333333336\n",
      "\n",
      " EPOCH 81/1000 \t train loss 5.18166073885831 \t val loss 8.779839197794596\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.46\n",
      "\n",
      " EPOCH 82/1000 \t train loss 5.131132559342817 \t val loss 8.732334772745768\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.4633333333333333\n",
      "\n",
      " EPOCH 83/1000 \t train loss 5.05457516150041 \t val loss 8.549946149190268\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 84/1000 \t train loss 4.999062516472557 \t val loss 8.54874070485433\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.4533333333333333\n",
      "\n",
      " EPOCH 85/1000 \t train loss 4.933548970655962 \t val loss 8.26547114054362\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 86/1000 \t train loss 4.847674824974754 \t val loss 8.2895876566569\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 87/1000 \t train loss 4.792866511778398 \t val loss 8.0878267288208\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 88/1000 \t train loss 4.736836996945468 \t val loss 8.075802167256674\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.4633333333333333\n",
      "\n",
      " EPOCH 89/1000 \t train loss 4.676189596002752 \t val loss 8.091829935709635\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.44333333333333336\n",
      "\n",
      " EPOCH 90/1000 \t train loss 4.618899952281605 \t val loss 7.9129288991292315\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.45\n",
      "\n",
      " EPOCH 91/1000 \t train loss 4.559698429974643 \t val loss 7.827191352844238\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 92/1000 \t train loss 4.513307744806463 \t val loss 7.679427782694499\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.44666666666666666\n",
      "\n",
      " EPOCH 93/1000 \t train loss 4.456770051609386 \t val loss 7.624507904052734\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 94/1000 \t train loss 4.41151744669134 \t val loss 7.400215943654378\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.4766666666666667\n",
      "\n",
      " EPOCH 95/1000 \t train loss 4.351403734900734 \t val loss 7.373091379801433\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.4533333333333333\n",
      "\n",
      " EPOCH 96/1000 \t train loss 4.303355390375311 \t val loss 7.329845428466797\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.4633333333333333\n",
      "\n",
      " EPOCH 97/1000 \t train loss 4.258989897641269 \t val loss 7.210994879404704\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 98/1000 \t train loss 4.207314729690552 \t val loss 7.056562582651774\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.46\n",
      "\n",
      " EPOCH 99/1000 \t train loss 4.158323309638283 \t val loss 7.025235017140706\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 100/1000 \t train loss 4.114028063687411 \t val loss 6.877254645029704\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.4633333333333333\n",
      "\n",
      " EPOCH 101/1000 \t train loss 4.070812983946367 \t val loss 6.856848239898682\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.4766666666666667\n",
      "\n",
      " EPOCH 102/1000 \t train loss 4.019792654297569 \t val loss 6.704638481140137\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 103/1000 \t train loss 3.9838930801911787 \t val loss 6.703746795654297\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.4766666666666667\n",
      "\n",
      " EPOCH 104/1000 \t train loss 3.9327824874357744 \t val loss 6.555790901184082\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.47\n",
      "\n",
      " EPOCH 105/1000 \t train loss 3.8951988978819414 \t val loss 6.535977840423584\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 106/1000 \t train loss 3.850373549894853 \t val loss 6.4314656257629395\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 107/1000 \t train loss 3.812237717888572 \t val loss 6.366189638773601\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 108/1000 \t train loss 3.7731761173768477 \t val loss 6.2945512135823565\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 109/1000 \t train loss 3.721220514991067 \t val loss 6.266641775767009\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.45666666666666667\n",
      "\n",
      " EPOCH 110/1000 \t train loss 3.6873753287575464 \t val loss 6.129691123962402\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.4766666666666667\n",
      "\n",
      " EPOCH 111/1000 \t train loss 3.650568496097218 \t val loss 6.187118848164876\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.47\n",
      "\n",
      " EPOCH 112/1000 \t train loss 3.6124969720840454 \t val loss 6.017171541849772\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.4666666666666667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 113/1000 \t train loss 3.5715221383354883 \t val loss 6.005336761474609\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 114/1000 \t train loss 3.5355386950752954 \t val loss 5.873907725016276\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.48333333333333334\n",
      "\n",
      " EPOCH 115/1000 \t train loss 3.498249140652743 \t val loss 5.896636962890625\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 116/1000 \t train loss 3.4607515118338843 \t val loss 5.863053321838379\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.4633333333333333\n",
      "\n",
      " EPOCH 117/1000 \t train loss 3.4295109402049673 \t val loss 5.724290053049724\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 118/1000 \t train loss 3.3987261165272105 \t val loss 5.656322320302327\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.47\n",
      "\n",
      " EPOCH 119/1000 \t train loss 3.3617325696078213 \t val loss 5.678304036458333\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 120/1000 \t train loss 3.323658661408858 \t val loss 5.547833760579427\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 121/1000 \t train loss 3.297491951422258 \t val loss 5.613475958506267\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 122/1000 \t train loss 3.2634500590237705 \t val loss 5.4594879150390625\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.4766666666666667\n",
      "\n",
      " EPOCH 123/1000 \t train loss 3.230755264108831 \t val loss 5.5226813952128095\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.45\n",
      "\n",
      " EPOCH 124/1000 \t train loss 3.2038895867087622 \t val loss 5.470142523447673\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.4633333333333333\n",
      "\n",
      " EPOCH 125/1000 \t train loss 3.1705540960485283 \t val loss 5.391171296437581\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.45666666666666667\n",
      "\n",
      " EPOCH 126/1000 \t train loss 3.1435096697373823 \t val loss 5.261414845784505\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 127/1000 \t train loss 3.1089823137630117 \t val loss 5.426728407541911\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.45\n",
      "\n",
      " EPOCH 128/1000 \t train loss 3.0768942616202613 \t val loss 5.196747461954753\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.47\n",
      "\n",
      " EPOCH 129/1000 \t train loss 3.0518035238439385 \t val loss 5.1447804768880205\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.4766666666666667\n",
      "\n",
      " EPOCH 130/1000 \t train loss 3.021232767538591 \t val loss 5.195574919382731\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.46\n",
      "\n",
      " EPOCH 131/1000 \t train loss 2.99111393364993 \t val loss 5.025099277496338\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.48\n",
      "\n",
      " EPOCH 132/1000 \t train loss 2.962264570322904 \t val loss 5.084620634714763\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.4766666666666667\n",
      "\n",
      " EPOCH 133/1000 \t train loss 2.928959358822216 \t val loss 4.958462556203206\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.48333333333333334\n",
      "\n",
      " EPOCH 134/1000 \t train loss 2.90542209148407 \t val loss 4.924378236134847\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.48\n",
      "\n",
      " EPOCH 135/1000 \t train loss 2.8762752684679898 \t val loss 4.902846495310466\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.4633333333333333\n",
      "\n",
      " EPOCH 136/1000 \t train loss 2.8448981696909126 \t val loss 4.8515520095825195\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.49\n",
      "\n",
      " EPOCH 137/1000 \t train loss 2.8207765275781806 \t val loss 4.802168846130371\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.47\n",
      "\n",
      " EPOCH 138/1000 \t train loss 2.7922980893741953 \t val loss 4.781906604766846\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.4866666666666667\n",
      "\n",
      " EPOCH 139/1000 \t train loss 2.7710671424865723 \t val loss 4.761304060618083\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.45\n",
      "\n",
      " EPOCH 140/1000 \t train loss 2.738482258536599 \t val loss 4.730774879455566\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 141/1000 \t train loss 2.712585687637329 \t val loss 4.655780792236328\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 142/1000 \t train loss 2.6835288026116113 \t val loss 4.6548542976379395\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.48333333333333334\n",
      "\n",
      " EPOCH 143/1000 \t train loss 2.6598583568226206 \t val loss 4.574862798055013\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.47\n",
      "\n",
      " EPOCH 144/1000 \t train loss 2.633467424999584 \t val loss 4.536169211069743\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.4766666666666667\n",
      "\n",
      " EPOCH 145/1000 \t train loss 2.610659967769276 \t val loss 4.547524452209473\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 146/1000 \t train loss 2.5826176513325083 \t val loss 4.531368573506673\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.49333333333333335\n",
      "\n",
      " EPOCH 147/1000 \t train loss 2.5538426529277456 \t val loss 4.427263100941976\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.48\n",
      "\n",
      " EPOCH 148/1000 \t train loss 2.5328431021083486 \t val loss 4.424794514973958\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 149/1000 \t train loss 2.507243048061024 \t val loss 4.391674200693767\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.48\n",
      "\n",
      " EPOCH 150/1000 \t train loss 2.481407252225009 \t val loss 4.346768220265706\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.49\n",
      "\n",
      " EPOCH 151/1000 \t train loss 2.460842327638106 \t val loss 4.3841471672058105\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.47\n",
      "\n",
      " EPOCH 152/1000 \t train loss 2.4371807250109585 \t val loss 4.388915220896403\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 153/1000 \t train loss 2.41163508458571 \t val loss 4.283760706583659\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.48\n",
      "\n",
      " EPOCH 154/1000 \t train loss 2.3908452770926734 \t val loss 4.253457705179851\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.4766666666666667\n",
      "\n",
      " EPOCH 155/1000 \t train loss 2.366178111596541 \t val loss 4.251964569091797\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.48333333333333334\n",
      "\n",
      " EPOCH 156/1000 \t train loss 2.3412002216685903 \t val loss 4.243431409200032\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.49\n",
      "\n",
      " EPOCH 157/1000 \t train loss 2.321290449662642 \t val loss 4.158668677012126\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.48333333333333334\n",
      "\n",
      " EPOCH 158/1000 \t train loss 2.2964137575843115 \t val loss 4.176739692687988\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 159/1000 \t train loss 2.2754680568521675 \t val loss 4.0937455495198565\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.48\n",
      "\n",
      " EPOCH 160/1000 \t train loss 2.2479394349184902 \t val loss 4.078296184539795\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.47\n",
      "\n",
      " EPOCH 161/1000 \t train loss 2.2300977381792935 \t val loss 4.027068297068278\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.48\n",
      "\n",
      " EPOCH 162/1000 \t train loss 2.2091240774501455 \t val loss 4.01082976659139\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.48\n",
      "\n",
      " EPOCH 163/1000 \t train loss 2.1823846968737515 \t val loss 4.006843725840251\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.4766666666666667\n",
      "\n",
      " EPOCH 164/1000 \t train loss 2.1610935818065298 \t val loss 3.9530763626098633\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.48333333333333334\n",
      "\n",
      " EPOCH 165/1000 \t train loss 2.1404096971858633 \t val loss 3.940934181213379\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 166/1000 \t train loss 2.1183373602953823 \t val loss 4.019541263580322\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.4866666666666667\n",
      "\n",
      " EPOCH 167/1000 \t train loss 2.099618998440829 \t val loss 3.902641216913859\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 168/1000 \t train loss 2.074005365371704 \t val loss 3.8845271269480386\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.4633333333333333\n",
      "\n",
      " EPOCH 169/1000 \t train loss 2.0491022305055098 \t val loss 3.8630801836649575\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 170/1000 \t train loss 2.0324087901548906 \t val loss 3.8185128370920816\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 171/1000 \t train loss 2.016300916671753 \t val loss 3.8425145943959556\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 172/1000 \t train loss 1.994170367717743 \t val loss 3.7852776845296225\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.47\n",
      "\n",
      " EPOCH 173/1000 \t train loss 1.975553268736059 \t val loss 3.799332618713379\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.4866666666666667\n",
      "\n",
      " EPOCH 174/1000 \t train loss 1.9534634080800144 \t val loss 3.7690930366516113\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 175/1000 \t train loss 1.9294152639128945 \t val loss 3.7175021171569824\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.4766666666666667\n",
      "\n",
      " EPOCH 176/1000 \t train loss 1.9120618321678855 \t val loss 3.684414863586426\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 177/1000 \t train loss 1.8902147791602395 \t val loss 3.6767019430796304\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.4633333333333333\n",
      "\n",
      " EPOCH 178/1000 \t train loss 1.8738427053798328 \t val loss 3.6728952725728354\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.4766666666666667\n",
      "\n",
      " EPOCH 179/1000 \t train loss 1.8540482195940884 \t val loss 3.6856658458709717\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.48333333333333334\n",
      "\n",
      " EPOCH 180/1000 \t train loss 1.8387294520031323 \t val loss 3.616471529006958\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.4766666666666667\n",
      "\n",
      " EPOCH 181/1000 \t train loss 1.8131676045331089 \t val loss 3.6146552562713623\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.4866666666666667\n",
      "\n",
      " EPOCH 182/1000 \t train loss 1.79442913423885 \t val loss 3.570526917775472\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.47\n",
      "\n",
      " EPOCH 183/1000 \t train loss 1.7759172916412354 \t val loss 3.56365966796875\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.47\n",
      "\n",
      " EPOCH 184/1000 \t train loss 1.7593603621829639 \t val loss 3.5176979700724282\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.4633333333333333\n",
      "\n",
      " EPOCH 185/1000 \t train loss 1.7397618943994695 \t val loss 3.5411794980367026\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.48333333333333334\n",
      "\n",
      " EPOCH 186/1000 \t train loss 1.7195618586106733 \t val loss 3.5362226168314614\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.49666666666666665\n",
      "\n",
      " EPOCH 187/1000 \t train loss 1.701860081065785 \t val loss 3.5878447691599527\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.47333333333333333\n",
      "\n",
      " EPOCH 188/1000 \t train loss 1.7068196047436108 \t val loss 3.5565804640452066\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.45666666666666667\n",
      "\n",
      " EPOCH 189/1000 \t train loss 1.6765175678513267 \t val loss 3.507448434829712\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.4666666666666667\n",
      "\n",
      " EPOCH 190/1000 \t train loss 1.6577469218860974 \t val loss 3.48691987991333\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.5033333333333333\n",
      "\n",
      " EPOCH 191/1000 \t train loss 1.6398942253806374 \t val loss 3.4922470251719155\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.48\n",
      "\n",
      " EPOCH 192/1000 \t train loss 1.6177304766394875 \t val loss 3.427187522252401\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.49333333333333335\n",
      "\n",
      " EPOCH 193/1000 \t train loss 1.6027718565680764 \t val loss 3.417292912801107\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.48333333333333334\n",
      "\n",
      " EPOCH 194/1000 \t train loss 1.5844460996714504 \t val loss 3.4208219846089682\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.48333333333333334\n",
      "\n",
      " EPOCH 195/1000 \t train loss 1.566780225797133 \t val loss 3.3586250146230063\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.48333333333333334\n",
      "\n",
      " EPOCH 196/1000 \t train loss 1.5539598844268105 \t val loss 3.413914442062378\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5\n",
      "\n",
      " EPOCH 197/1000 \t train loss 1.535798972303217 \t val loss 3.3662741978963218\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.49333333333333335\n",
      "\n",
      " EPOCH 198/1000 \t train loss 1.5196956233544783 \t val loss 3.4097582499186196\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.48\n",
      "\n",
      " EPOCH 199/1000 \t train loss 1.502910229292783 \t val loss 3.3904659748077393\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.48\n",
      "\n",
      " EPOCH 200/1000 \t train loss 1.4889877330173145 \t val loss 3.2886664867401123\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.48333333333333334\n",
      "\n",
      " EPOCH 201/1000 \t train loss 1.468292068351399 \t val loss 3.306525627772013\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.49333333333333335\n",
      "\n",
      " EPOCH 202/1000 \t train loss 1.4543109969659285 \t val loss 3.265608628590902\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.49\n",
      "\n",
      " EPOCH 203/1000 \t train loss 1.4439147223125806 \t val loss 3.2557830015818277\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.49333333333333335\n",
      "\n",
      " EPOCH 204/1000 \t train loss 1.4234468178315596 \t val loss 3.235888719558716\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.49\n",
      "\n",
      " EPOCH 205/1000 \t train loss 1.4104470177130266 \t val loss 3.231334924697876\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.49\n",
      "\n",
      " EPOCH 206/1000 \t train loss 1.3944400386376814 \t val loss 3.1924242973327637\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5133333333333333\n",
      "\n",
      " EPOCH 207/1000 \t train loss 1.3824040998112073 \t val loss 3.217825492223104\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.4866666666666667\n",
      "\n",
      " EPOCH 208/1000 \t train loss 1.3656624122099443 \t val loss 3.2007489999135337\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.49666666666666665\n",
      "\n",
      " EPOCH 209/1000 \t train loss 1.3505197221582586 \t val loss 3.2184600035349527\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.51\n",
      "\n",
      " EPOCH 210/1000 \t train loss 1.3388303030620923 \t val loss 3.230842192967733\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.51\n",
      "\n",
      " EPOCH 211/1000 \t train loss 1.3259522806514392 \t val loss 3.1932473182678223\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.5\n",
      "\n",
      " EPOCH 212/1000 \t train loss 1.3086261369965293 \t val loss 3.2092018922170005\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.51\n",
      "\n",
      " EPOCH 213/1000 \t train loss 1.2942163131453774 \t val loss 3.218006451924642\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5033333333333333\n",
      "\n",
      " EPOCH 214/1000 \t train loss 1.2858192216266284 \t val loss 3.2116243839263916\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.5066666666666667\n",
      "\n",
      " EPOCH 215/1000 \t train loss 1.2657615000551397 \t val loss 3.1306374867757163\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.5066666666666667\n",
      "\n",
      " EPOCH 216/1000 \t train loss 1.2551999471404336 \t val loss 3.107631047566732\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.49666666666666665\n",
      "\n",
      " EPOCH 217/1000 \t train loss 1.2408360026099465 \t val loss 3.106508413950602\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.5066666666666667\n",
      "\n",
      " EPOCH 218/1000 \t train loss 1.222178491679105 \t val loss 3.0987297693888345\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5066666666666667\n",
      "\n",
      " EPOCH 219/1000 \t train loss 1.2091676917943088 \t val loss 3.1146562894185386\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5\n",
      "\n",
      " EPOCH 220/1000 \t train loss 1.199174252423373 \t val loss 3.0566919644673667\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.5\n",
      "\n",
      " EPOCH 221/1000 \t train loss 1.1871419494802302 \t val loss 3.098039229710897\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5033333333333333\n",
      "\n",
      " EPOCH 222/1000 \t train loss 1.1770093495195562 \t val loss 3.058976173400879\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5133333333333333\n",
      "\n",
      " EPOCH 223/1000 \t train loss 1.1665324839678677 \t val loss 3.0891740322113037\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.52\n",
      "\n",
      " EPOCH 224/1000 \t train loss 1.1506977568973193 \t val loss 3.1349610487620034\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5433333333333333\n",
      "\n",
      " EPOCH 225/1000 \t train loss 1.139802022413774 \t val loss 3.1247951984405518\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.5366666666666666\n",
      "\n",
      " EPOCH 226/1000 \t train loss 1.1262764876539058 \t val loss 3.0407538414001465\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.5366666666666666\n",
      "\n",
      " EPOCH 227/1000 \t train loss 1.110361863266338 \t val loss 2.9912240505218506\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5233333333333333\n",
      "\n",
      " EPOCH 228/1000 \t train loss 1.1001768491484902 \t val loss 2.950033267339071\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.5233333333333333\n",
      "\n",
      " EPOCH 229/1000 \t train loss 1.0829507112503052 \t val loss 2.9464872678120932\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.52\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 230/1000 \t train loss 1.0695044560865923 \t val loss 2.9210872650146484\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.52\n",
      "\n",
      " EPOCH 231/1000 \t train loss 1.0647175745530562 \t val loss 2.9197112719217935\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5233333333333333\n",
      "\n",
      " EPOCH 232/1000 \t train loss 1.0487154505469582 \t val loss 2.923149903615316\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5333333333333333\n",
      "\n",
      " EPOCH 233/1000 \t train loss 1.0412578636949712 \t val loss 2.9607733885447183\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5233333333333333\n",
      "\n",
      " EPOCH 234/1000 \t train loss 1.027647004886107 \t val loss 2.9581642150878906\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.5433333333333333\n",
      "\n",
      " EPOCH 235/1000 \t train loss 1.0156967639923096 \t val loss 2.9410335222880044\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.5333333333333333\n",
      "\n",
      " EPOCH 236/1000 \t train loss 1.0015803575515747 \t val loss 2.898392677307129\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5266666666666666\n",
      "\n",
      " EPOCH 237/1000 \t train loss 0.9919797046618029 \t val loss 2.873128652572632\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.5366666666666666\n",
      "\n",
      " EPOCH 238/1000 \t train loss 0.9806216657161713 \t val loss 2.8764267762502036\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.5333333333333333\n",
      "\n",
      " EPOCH 239/1000 \t train loss 0.9696619754487817 \t val loss 2.888211965560913\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.5366666666666666\n",
      "\n",
      " EPOCH 240/1000 \t train loss 0.9596321257677946 \t val loss 2.9280715783437095\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5266666666666666\n",
      "\n",
      " EPOCH 241/1000 \t train loss 0.9474583728746935 \t val loss 2.833158254623413\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.5433333333333333\n",
      "\n",
      " EPOCH 242/1000 \t train loss 0.9364266422661868 \t val loss 2.8403520584106445\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5433333333333333\n",
      "\n",
      " EPOCH 243/1000 \t train loss 0.92693338339979 \t val loss 2.816302537918091\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.5433333333333333\n",
      "\n",
      " EPOCH 244/1000 \t train loss 0.9130738160826943 \t val loss 2.8311262925465903\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.5333333333333333\n",
      "\n",
      " EPOCH 245/1000 \t train loss 0.9080828374082391 \t val loss 2.7848244508107505\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.54\n",
      "\n",
      " EPOCH 246/1000 \t train loss 0.8949494578621604 \t val loss 2.7691383361816406\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5466666666666666\n",
      "\n",
      " EPOCH 247/1000 \t train loss 0.8867747783660889 \t val loss 2.791181484858195\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.55\n",
      "\n",
      " EPOCH 248/1000 \t train loss 0.8770990236239 \t val loss 2.8573549588521323\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.5366666666666666\n",
      "\n",
      " EPOCH 249/1000 \t train loss 0.8717736114155162 \t val loss 2.877061446507772\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.53\n",
      "\n",
      " EPOCH 250/1000 \t train loss 0.8584755523638292 \t val loss 2.839787483215332\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5366666666666666\n",
      "\n",
      " EPOCH 251/1000 \t train loss 0.8496452597054568 \t val loss 2.777428309122721\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.5533333333333333\n",
      "\n",
      " EPOCH 252/1000 \t train loss 0.842358646067706 \t val loss 2.7398722966512046\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5433333333333333\n",
      "\n",
      " EPOCH 253/1000 \t train loss 0.8307750170881097 \t val loss 2.7908894220987954\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.55\n",
      "\n",
      " EPOCH 254/1000 \t train loss 0.8235210613770918 \t val loss 2.699289083480835\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.54\n",
      "\n",
      " EPOCH 255/1000 \t train loss 0.809648643840443 \t val loss 2.6847888628641763\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.5433333333333333\n",
      "\n",
      " EPOCH 256/1000 \t train loss 0.8048530302264474 \t val loss 2.76255997021993\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5533333333333333\n",
      "\n",
      " EPOCH 257/1000 \t train loss 0.7945963821627877 \t val loss 2.8176259199778237\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5533333333333333\n",
      "\n",
      " EPOCH 258/1000 \t train loss 0.7858851552009583 \t val loss 2.742170254389445\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.5366666666666666\n",
      "\n",
      " EPOCH 259/1000 \t train loss 0.7805558822371743 \t val loss 2.770021915435791\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5566666666666666\n",
      "\n",
      " EPOCH 260/1000 \t train loss 0.7699476155367765 \t val loss 2.721470276514689\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.55\n",
      "\n",
      " EPOCH 261/1000 \t train loss 0.7636971852996133 \t val loss 2.748721440633138\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.5266666666666666\n",
      "\n",
      " EPOCH 262/1000 \t train loss 0.7572534734552557 \t val loss 2.668494701385498\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5533333333333333\n",
      "\n",
      " EPOCH 263/1000 \t train loss 0.7482385689562018 \t val loss 2.7758565743764243\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.54\n",
      "\n",
      " EPOCH 264/1000 \t train loss 0.7488387308337472 \t val loss 2.746957858403524\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.56\n",
      "\n",
      " EPOCH 265/1000 \t train loss 0.7424564415758307 \t val loss 2.8604265054066977\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.5733333333333334\n",
      "\n",
      " EPOCH 266/1000 \t train loss 0.7343863032080911 \t val loss 2.859130620956421\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.56\n",
      "\n",
      " EPOCH 267/1000 \t train loss 0.7230248586698012 \t val loss 2.690317074457804\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.55\n",
      "\n",
      " EPOCH 268/1000 \t train loss 0.71129248900847 \t val loss 2.643599510192871\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.5433333333333333\n",
      "\n",
      " EPOCH 269/1000 \t train loss 0.7021021572026339 \t val loss 2.621248722076416\n",
      "train accuracy 0.9884801189149015 \t val accuracy 0.5466666666666666\n",
      "\n",
      " EPOCH 270/1000 \t train loss 0.6895782405679877 \t val loss 2.5412117640177407\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5666666666666667\n",
      "\n",
      " EPOCH 271/1000 \t train loss 0.6800330281257629 \t val loss 2.555736223856608\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.5633333333333334\n",
      "\n",
      " EPOCH 272/1000 \t train loss 0.6703468479893424 \t val loss 2.566132386525472\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.57\n",
      "\n",
      " EPOCH 273/1000 \t train loss 0.6644199761477384 \t val loss 2.5264278252919516\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.5733333333333334\n",
      "\n",
      " EPOCH 274/1000 \t train loss 0.6568113782189109 \t val loss 2.4735492865244546\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.5666666666666667\n",
      "\n",
      " EPOCH 275/1000 \t train loss 0.6486929113214667 \t val loss 2.4650680224100747\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.5666666666666667\n",
      "\n",
      " EPOCH 276/1000 \t train loss 0.6418323164636438 \t val loss 2.456634759902954\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5666666666666667\n",
      "\n",
      " EPOCH 277/1000 \t train loss 0.637915001674132 \t val loss 2.524700164794922\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 278/1000 \t train loss 0.6291774050755934 \t val loss 2.569679021835327\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.5833333333333334\n",
      "\n",
      " EPOCH 279/1000 \t train loss 0.623882380398837 \t val loss 2.467744986216227\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.56\n",
      "\n",
      " EPOCH 280/1000 \t train loss 0.6165787008675662 \t val loss 2.4106620152791343\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.5833333333333334\n",
      "\n",
      " EPOCH 281/1000 \t train loss 0.6114139692349867 \t val loss 2.4512106577555337\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.5433333333333333\n",
      "\n",
      " EPOCH 282/1000 \t train loss 0.6040498885241422 \t val loss 2.383183161417643\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.57\n",
      "\n",
      " EPOCH 283/1000 \t train loss 0.6022403158924796 \t val loss 2.456836462020874\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.58\n",
      "\n",
      " EPOCH 284/1000 \t train loss 0.5965889313004233 \t val loss 2.7155090967814126\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.5633333333333334\n",
      "\n",
      " EPOCH 285/1000 \t train loss 0.5956381992860273 \t val loss 2.7693626085917153\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5533333333333333\n",
      "\n",
      " EPOCH 286/1000 \t train loss 0.6001134975390001 \t val loss 2.4790638287862143\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.58\n",
      "\n",
      " EPOCH 287/1000 \t train loss 0.6003222682259299 \t val loss 2.682856321334839\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.5133333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 288/1000 \t train loss 0.6094552874565125 \t val loss 3.2206323941548667\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.48\n",
      "\n",
      " EPOCH 289/1000 \t train loss 0.6530279815196991 \t val loss 3.0485754013061523\n",
      "train accuracy 0.9788182831661093 \t val accuracy 0.5366666666666666\n",
      "\n",
      " EPOCH 290/1000 \t train loss 0.7338757108558308 \t val loss 2.9354286193847656\n",
      "train accuracy 0.9565217391304348 \t val accuracy 0.5566666666666666\n",
      "\n",
      " EPOCH 291/1000 \t train loss 0.7599336288192056 \t val loss 3.145603815714518\n",
      "train accuracy 0.967670011148272 \t val accuracy 0.5233333333333333\n",
      "\n",
      " EPOCH 292/1000 \t train loss 0.7251800163225695 \t val loss 2.7052637736002603\n",
      "train accuracy 0.9817911557041992 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 293/1000 \t train loss 0.6760270974852822 \t val loss 2.690209945042928\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6033333333333334\n",
      "\n",
      " EPOCH 294/1000 \t train loss 0.6487507793036374 \t val loss 2.6034138997395835\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 295/1000 \t train loss 0.6292409084059976 \t val loss 2.5315412680308023\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5833333333333334\n",
      "\n",
      " EPOCH 296/1000 \t train loss 0.6132273348894987 \t val loss 2.4757773876190186\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 297/1000 \t train loss 0.5989554361863569 \t val loss 2.4307943979899087\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 298/1000 \t train loss 0.5878528329459104 \t val loss 2.375307083129883\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 299/1000 \t train loss 0.5779662105170164 \t val loss 2.3348697821299234\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 300/1000 \t train loss 0.5676699497482993 \t val loss 2.2947467962900796\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 301/1000 \t train loss 0.5596465062011372 \t val loss 2.270234306653341\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 302/1000 \t train loss 0.5513839748772708 \t val loss 2.2402567068735757\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.5966666666666667\n",
      "\n",
      " EPOCH 303/1000 \t train loss 0.5443160181695764 \t val loss 2.2093759377797446\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 304/1000 \t train loss 0.5372948077591982 \t val loss 2.1974680423736572\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.5966666666666667\n",
      "\n",
      " EPOCH 305/1000 \t train loss 0.5319108719175513 \t val loss 2.174684921900431\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6\n",
      "\n",
      " EPOCH 306/1000 \t train loss 0.5265427150509574 \t val loss 2.1530984242757163\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6\n",
      "\n",
      " EPOCH 307/1000 \t train loss 0.521475603634661 \t val loss 2.1455196539560952\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.61\n",
      "\n",
      " EPOCH 308/1000 \t train loss 0.5143919519402764 \t val loss 2.1379156510035195\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 309/1000 \t train loss 0.510710977695205 \t val loss 2.130885044733683\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5966666666666667\n",
      "\n",
      " EPOCH 310/1000 \t train loss 0.5050061426379464 \t val loss 2.111921707789103\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 311/1000 \t train loss 0.50137928805568 \t val loss 2.105284849802653\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 312/1000 \t train loss 0.4963770386847583 \t val loss 2.0931116342544556\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 313/1000 \t train loss 0.4930654452605681 \t val loss 2.08247439066569\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 314/1000 \t train loss 0.48915308713912964 \t val loss 2.0924675861994424\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 315/1000 \t train loss 0.4855541790073568 \t val loss 2.0741944313049316\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 316/1000 \t train loss 0.4801846458153291 \t val loss 2.0699577728907266\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 317/1000 \t train loss 0.476819860664281 \t val loss 2.057434638341268\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6033333333333334\n",
      "\n",
      " EPOCH 318/1000 \t train loss 0.47307131778110156 \t val loss 2.064837416013082\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 319/1000 \t train loss 0.47014161944389343 \t val loss 2.059553941090902\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 320/1000 \t train loss 0.4665935242717916 \t val loss 2.064588944117228\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 321/1000 \t train loss 0.46426124464381824 \t val loss 2.0542702674865723\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 322/1000 \t train loss 0.4598870561881499 \t val loss 2.0421900351842246\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 323/1000 \t train loss 0.45722340182824567 \t val loss 2.032110055287679\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 324/1000 \t train loss 0.4527342766523361 \t val loss 2.0349122683207193\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 325/1000 \t train loss 0.45047544078393414 \t val loss 2.034144083658854\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5966666666666667\n",
      "\n",
      " EPOCH 326/1000 \t train loss 0.44762254845012317 \t val loss 2.0370070139567056\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 327/1000 \t train loss 0.4431465796448968 \t val loss 2.0160425106684365\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 328/1000 \t train loss 0.4413500848141583 \t val loss 2.0256540775299072\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 329/1000 \t train loss 0.438131028955633 \t val loss 2.0251518090566\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 330/1000 \t train loss 0.43443208797411487 \t val loss 2.0155543883641562\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 331/1000 \t train loss 0.431952410123565 \t val loss 2.011930306752523\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5833333333333334\n",
      "\n",
      " EPOCH 332/1000 \t train loss 0.42925988137722015 \t val loss 2.008411089579264\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5833333333333334\n",
      "\n",
      " EPOCH 333/1000 \t train loss 0.42606130513277923 \t val loss 2.005521853764852\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 334/1000 \t train loss 0.4238632091067054 \t val loss 1.9815316597620647\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 335/1000 \t train loss 0.4218719574538144 \t val loss 1.9665412108103435\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 336/1000 \t train loss 0.4174610254439441 \t val loss 1.9819955825805664\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 337/1000 \t train loss 0.41470341926271265 \t val loss 1.9835755825042725\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.58\n",
      "\n",
      " EPOCH 338/1000 \t train loss 0.411750158125704 \t val loss 1.966269056002299\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 339/1000 \t train loss 0.4092523469166322 \t val loss 1.9560572306315105\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 340/1000 \t train loss 0.4085680151527578 \t val loss 1.945513367652893\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 341/1000 \t train loss 0.40559540553526446 \t val loss 1.9502075910568237\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.58\n",
      "\n",
      " EPOCH 342/1000 \t train loss 0.40309796820987354 \t val loss 1.9428541660308838\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.5966666666666667\n",
      "\n",
      " EPOCH 343/1000 \t train loss 0.39957328005270526 \t val loss 1.9410974184672039\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6\n",
      "\n",
      " EPOCH 344/1000 \t train loss 0.3977248573845083 \t val loss 1.9295129378636677\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 345/1000 \t train loss 0.3952594914219596 \t val loss 1.9181328614552815\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.5833333333333334\n",
      "\n",
      " EPOCH 346/1000 \t train loss 0.3941579095341943 \t val loss 1.9054766496022542\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.5933333333333334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 347/1000 \t train loss 0.39140512591058557 \t val loss 1.896046797434489\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 348/1000 \t train loss 0.38727774945172394 \t val loss 1.901981790860494\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.5833333333333334\n",
      "\n",
      " EPOCH 349/1000 \t train loss 0.3853886073285883 \t val loss 1.900859793027242\n",
      "train accuracy 0.9933110367892977 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 350/1000 \t train loss 0.38454191928560083 \t val loss 1.882686972618103\n",
      "train accuracy 0.9884801189149015 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 351/1000 \t train loss 0.38027675314383075 \t val loss 1.8809996048609416\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.5833333333333334\n",
      "\n",
      " EPOCH 352/1000 \t train loss 0.37830727208744397 \t val loss 1.880140741666158\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.5833333333333334\n",
      "\n",
      " EPOCH 353/1000 \t train loss 0.374724726785313 \t val loss 1.874064842859904\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 354/1000 \t train loss 0.3749316470189528 \t val loss 1.8586962223052979\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.5733333333333334\n",
      "\n",
      " EPOCH 355/1000 \t train loss 0.37234383008696814 \t val loss 1.857919692993164\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 356/1000 \t train loss 0.3701136586340991 \t val loss 1.8489899237950642\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 357/1000 \t train loss 0.36869199573993683 \t val loss 1.8274676005045574\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5966666666666667\n",
      "\n",
      " EPOCH 358/1000 \t train loss 0.36585177210244263 \t val loss 1.83820645014445\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.58\n",
      "\n",
      " EPOCH 359/1000 \t train loss 0.36415019766850903 \t val loss 1.8181703090667725\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 360/1000 \t train loss 0.3613958683880893 \t val loss 1.8251769542694092\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 361/1000 \t train loss 0.3600288968194615 \t val loss 1.8080272674560547\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6\n",
      "\n",
      " EPOCH 362/1000 \t train loss 0.3583589385856282 \t val loss 1.7884283860524495\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.5966666666666667\n",
      "\n",
      " EPOCH 363/1000 \t train loss 0.3553073460405523 \t val loss 1.789455811182658\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6\n",
      "\n",
      " EPOCH 364/1000 \t train loss 0.3540764491666447 \t val loss 1.8055464426676433\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6033333333333334\n",
      "\n",
      " EPOCH 365/1000 \t train loss 0.35359011725945905 \t val loss 1.7841115395228069\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 366/1000 \t train loss 0.3513448251919313 \t val loss 1.7675901254018147\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 367/1000 \t train loss 0.3512943454764106 \t val loss 1.7491946617762248\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.61\n",
      "\n",
      " EPOCH 368/1000 \t train loss 0.349611298604445 \t val loss 1.7564061482747395\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6066666666666667\n",
      "\n",
      " EPOCH 369/1000 \t train loss 0.346821356903423 \t val loss 1.7531496683756511\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6\n",
      "\n",
      " EPOCH 370/1000 \t train loss 0.34642466496337543 \t val loss 1.7250383694966633\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 371/1000 \t train loss 0.34280385889790277 \t val loss 1.792656143506368\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 372/1000 \t train loss 0.3429233418269591 \t val loss 1.7666422526041667\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.61\n",
      "\n",
      " EPOCH 373/1000 \t train loss 0.3432663489471782 \t val loss 1.7330131530761719\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.5966666666666667\n",
      "\n",
      " EPOCH 374/1000 \t train loss 0.3406589315696196 \t val loss 1.7255293528238933\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.5833333333333334\n",
      "\n",
      " EPOCH 375/1000 \t train loss 0.3369001773270694 \t val loss 1.7088323831558228\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6\n",
      "\n",
      " EPOCH 376/1000 \t train loss 0.3382349678061225 \t val loss 1.7589617570241292\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6\n",
      "\n",
      " EPOCH 377/1000 \t train loss 0.3378651751713319 \t val loss 1.8116360505421956\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.62\n",
      "\n",
      " EPOCH 378/1000 \t train loss 0.3373973342505368 \t val loss 1.7703664700190227\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6233333333333333\n",
      "\n",
      " EPOCH 379/1000 \t train loss 0.3354252116246657 \t val loss 1.7110082308451335\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 380/1000 \t train loss 0.3340954130346125 \t val loss 1.7469393014907837\n",
      "train accuracy 0.9933110367892977 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 381/1000 \t train loss 0.33322417600588367 \t val loss 1.685049057006836\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.63\n",
      "\n",
      " EPOCH 382/1000 \t train loss 0.33202206817540253 \t val loss 1.81118639310201\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6133333333333333\n",
      "\n",
      " EPOCH 383/1000 \t train loss 0.3303460492329164 \t val loss 1.7408105532328289\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.6166666666666667\n",
      "\n",
      " EPOCH 384/1000 \t train loss 0.3316553086042404 \t val loss 1.6827987432479858\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.59\n",
      "\n",
      " EPOCH 385/1000 \t train loss 0.32908993688496674 \t val loss 1.7637357314427693\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 386/1000 \t train loss 0.3328562920743769 \t val loss 1.6925694942474365\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6066666666666667\n",
      "\n",
      " EPOCH 387/1000 \t train loss 0.3408666524020108 \t val loss 1.685939073562622\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 388/1000 \t train loss 0.3465224788947539 \t val loss 2.2778764963150024\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.5666666666666667\n",
      "\n",
      " EPOCH 389/1000 \t train loss 0.37862926721572876 \t val loss 2.6961704889933267\n",
      "train accuracy 0.9851356373095503 \t val accuracy 0.55\n",
      "\n",
      " EPOCH 390/1000 \t train loss 0.46265884150158276 \t val loss 2.069880644480387\n",
      "train accuracy 0.9669267930137495 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 391/1000 \t train loss 0.48903595723889093 \t val loss 2.458463986714681\n",
      "train accuracy 0.9698996655518395 \t val accuracy 0.5733333333333334\n",
      "\n",
      " EPOCH 392/1000 \t train loss 0.47045768932862714 \t val loss 2.1074339548746743\n",
      "train accuracy 0.9836492010405053 \t val accuracy 0.6366666666666667\n",
      "\n",
      " EPOCH 393/1000 \t train loss 0.43469731645150617 \t val loss 1.9401799043019612\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 394/1000 \t train loss 0.40678677233782684 \t val loss 1.8330026467641194\n",
      "train accuracy 0.9933110367892977 \t val accuracy 0.6333333333333333\n",
      "\n",
      " EPOCH 395/1000 \t train loss 0.3878217583352869 \t val loss 1.748702088991801\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.63\n",
      "\n",
      " EPOCH 396/1000 \t train loss 0.3718947483734651 \t val loss 1.686222513516744\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6333333333333333\n",
      "\n",
      " EPOCH 397/1000 \t train loss 0.35956288467754016 \t val loss 1.6513172785441081\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6233333333333333\n",
      "\n",
      " EPOCH 398/1000 \t train loss 0.3520992669192227 \t val loss 1.6243698199590046\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.63\n",
      "\n",
      " EPOCH 399/1000 \t train loss 0.3447722318497571 \t val loss 1.6046767632166545\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6333333333333333\n",
      "\n",
      " EPOCH 400/1000 \t train loss 0.3386416015299884 \t val loss 1.5884660482406616\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.6333333333333333\n",
      "\n",
      " EPOCH 401/1000 \t train loss 0.33352071995084936 \t val loss 1.5767854849497478\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 402/1000 \t train loss 0.3301231427626176 \t val loss 1.563970963160197\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 403/1000 \t train loss 0.32497678290713916 \t val loss 1.5555713176727295\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 404/1000 \t train loss 0.32114616713740607 \t val loss 1.5554253260294597\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6433333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 405/1000 \t train loss 0.31897925111380493 \t val loss 1.5539584159851074\n",
      "train accuracy 0.9936826458565589 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 406/1000 \t train loss 0.31670654632828454 \t val loss 1.548212726910909\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 407/1000 \t train loss 0.3126050586050207 \t val loss 1.544537623723348\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 408/1000 \t train loss 0.31121625006198883 \t val loss 1.5429275035858154\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 409/1000 \t train loss 0.3094471598213369 \t val loss 1.5317110220591228\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 410/1000 \t train loss 0.3077359470454129 \t val loss 1.5374050935109456\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 411/1000 \t train loss 0.3058775175701488 \t val loss 1.5355074803034465\n",
      "train accuracy 0.9933110367892977 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 412/1000 \t train loss 0.3058089573274959 \t val loss 1.5441185633341472\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 413/1000 \t train loss 0.30401885780421173 \t val loss 1.5360655387242634\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 414/1000 \t train loss 0.30312289568510925 \t val loss 1.5273878574371338\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 415/1000 \t train loss 0.2996742088686336 \t val loss 1.5237775643666585\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 416/1000 \t train loss 0.29946836016394873 \t val loss 1.5156426827112834\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 417/1000 \t train loss 0.298038359392773 \t val loss 1.5241928895314534\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 418/1000 \t train loss 0.2968997914682735 \t val loss 1.5268125931421916\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 419/1000 \t train loss 0.2948672405698083 \t val loss 1.521065632502238\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 420/1000 \t train loss 0.2954056452621113 \t val loss 1.5214662949244182\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 421/1000 \t train loss 0.29241910441355273 \t val loss 1.515801986058553\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 422/1000 \t train loss 0.2920708954334259 \t val loss 1.5170692602793376\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 423/1000 \t train loss 0.2927412201057781 \t val loss 1.5206311146418254\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 424/1000 \t train loss 0.29026445746421814 \t val loss 1.520137111345927\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 425/1000 \t train loss 0.2888361987742511 \t val loss 1.513037125269572\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 426/1000 \t train loss 0.28828411210667004 \t val loss 1.5196669896443684\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6366666666666667\n",
      "\n",
      " EPOCH 427/1000 \t train loss 0.2883065491914749 \t val loss 1.5204302072525024\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 428/1000 \t train loss 0.2870834781364961 \t val loss 1.5095793008804321\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 429/1000 \t train loss 0.28711720217357983 \t val loss 1.5105371475219727\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 430/1000 \t train loss 0.2845116433772174 \t val loss 1.5122168858846028\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 431/1000 \t train loss 0.2842491878704591 \t val loss 1.5068129698435466\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 432/1000 \t train loss 0.2847699103030292 \t val loss 1.5079595645268757\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 433/1000 \t train loss 0.28442365472966974 \t val loss 1.5318527619043987\n",
      "train accuracy 0.9933110367892977 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 434/1000 \t train loss 0.2846949114040895 \t val loss 1.5217117468516033\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6333333333333333\n",
      "\n",
      " EPOCH 435/1000 \t train loss 0.2818707945671948 \t val loss 1.5137627124786377\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6366666666666667\n",
      "\n",
      " EPOCH 436/1000 \t train loss 0.2833616692911495 \t val loss 1.5184634526570637\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 437/1000 \t train loss 0.2808445800434459 \t val loss 1.5074281692504883\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 438/1000 \t train loss 0.28033471649343317 \t val loss 1.5002835591634114\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6333333333333333\n",
      "\n",
      " EPOCH 439/1000 \t train loss 0.2795824015682394 \t val loss 1.4845255613327026\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.63\n",
      "\n",
      " EPOCH 440/1000 \t train loss 0.28091991625048895 \t val loss 1.4910409450531006\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 441/1000 \t train loss 0.280006005005403 \t val loss 1.489529291788737\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 442/1000 \t train loss 0.2782141593369571 \t val loss 1.488159457842509\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 443/1000 \t train loss 0.2768629410050132 \t val loss 1.4843843380610149\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6333333333333333\n",
      "\n",
      " EPOCH 444/1000 \t train loss 0.27637762237678876 \t val loss 1.477476437886556\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 445/1000 \t train loss 0.2749754176898436 \t val loss 1.474976380666097\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 446/1000 \t train loss 0.2743532508611679 \t val loss 1.4944652716318767\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 447/1000 \t train loss 0.27392932908101514 \t val loss 1.4752052625020344\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 448/1000 \t train loss 0.2739705335010182 \t val loss 1.4600361585617065\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 449/1000 \t train loss 0.2760964171452956 \t val loss 1.4681638081868489\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 450/1000 \t train loss 0.2748471457849849 \t val loss 1.522828221321106\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 451/1000 \t train loss 0.2760696763342077 \t val loss 1.5135500033696492\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 452/1000 \t train loss 0.2750658812848004 \t val loss 1.4729366302490234\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.63\n",
      "\n",
      " EPOCH 453/1000 \t train loss 0.27594792436469684 \t val loss 1.496544361114502\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 454/1000 \t train loss 0.2754236581650647 \t val loss 1.493718107541402\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 455/1000 \t train loss 0.277095304294066 \t val loss 1.5767667690912883\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 456/1000 \t train loss 0.27651487019929016 \t val loss 1.560866912206014\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6366666666666667\n",
      "\n",
      " EPOCH 457/1000 \t train loss 0.27720529111948883 \t val loss 1.476299484570821\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6333333333333333\n",
      "\n",
      " EPOCH 458/1000 \t train loss 0.2761883369900964 \t val loss 1.5159728129704793\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 459/1000 \t train loss 0.2777520634911277 \t val loss 1.465369462966919\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 460/1000 \t train loss 0.276025189594789 \t val loss 1.622033675511678\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6033333333333334\n",
      "\n",
      " EPOCH 461/1000 \t train loss 0.27722573415799573 \t val loss 1.5888896783192952\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6266666666666667\n",
      "\n",
      " EPOCH 462/1000 \t train loss 0.28290167450904846 \t val loss 1.5246876080830891\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6433333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 463/1000 \t train loss 0.28667609935457056 \t val loss 1.6217594544092815\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 464/1000 \t train loss 0.2899693101644516 \t val loss 1.6181823015213013\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 465/1000 \t train loss 0.29146584326570685 \t val loss 1.5747800668080647\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 466/1000 \t train loss 0.2919089062647386 \t val loss 1.53626815478007\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 467/1000 \t train loss 0.2865326445211064 \t val loss 1.4780378341674805\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.63\n",
      "\n",
      " EPOCH 468/1000 \t train loss 0.2779415669766339 \t val loss 1.469606836636861\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 469/1000 \t train loss 0.273048034445806 \t val loss 1.4359415769577026\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 470/1000 \t train loss 0.26820081133734097 \t val loss 1.4240493774414062\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 471/1000 \t train loss 0.26719674129377713 \t val loss 1.4103211164474487\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 472/1000 \t train loss 0.26395451548424637 \t val loss 1.4363993008931477\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 473/1000 \t train loss 0.26437036760828714 \t val loss 1.429731051127116\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 474/1000 \t train loss 0.2621365717866204 \t val loss 1.4099628527959187\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 475/1000 \t train loss 0.26169114763086493 \t val loss 1.4049570560455322\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 476/1000 \t train loss 0.26178483258594165 \t val loss 1.41877015431722\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 477/1000 \t train loss 0.2607992244037715 \t val loss 1.4463935295740764\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 478/1000 \t train loss 0.2615486512129957 \t val loss 1.4322676261266072\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 479/1000 \t train loss 0.26014980199662124 \t val loss 1.4161691665649414\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 480/1000 \t train loss 0.26456565071236005 \t val loss 1.4007891416549683\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 481/1000 \t train loss 0.26465110209855164 \t val loss 1.3927867412567139\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 482/1000 \t train loss 0.2634603191505779 \t val loss 1.5277984539667766\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 483/1000 \t train loss 0.2672036588191986 \t val loss 1.6650127569834392\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 484/1000 \t train loss 0.27502822469581256 \t val loss 1.5316526492436726\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 485/1000 \t train loss 0.2828493822704662 \t val loss 1.5882796446482341\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6066666666666667\n",
      "\n",
      " EPOCH 486/1000 \t train loss 0.30574822425842285 \t val loss 1.9399638175964355\n",
      "train accuracy 0.9869936826458565 \t val accuracy 0.5866666666666667\n",
      "\n",
      " EPOCH 487/1000 \t train loss 0.3783448040485382 \t val loss 1.6511849164962769\n",
      "train accuracy 0.9721293199554069 \t val accuracy 0.62\n",
      "\n",
      " EPOCH 488/1000 \t train loss 0.38131779161366547 \t val loss 1.7241419951121013\n",
      "train accuracy 0.9821627647714605 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 489/1000 \t train loss 0.3714564700018276 \t val loss 1.657990535100301\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 490/1000 \t train loss 0.3496543819254095 \t val loss 1.5575137535730998\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 491/1000 \t train loss 0.32663162729956885 \t val loss 1.4657497803370159\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 492/1000 \t train loss 0.30823263932358136 \t val loss 1.4165698289871216\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 493/1000 \t train loss 0.2977054051377557 \t val loss 1.3938368161519368\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 494/1000 \t train loss 0.2903227589347146 \t val loss 1.3856255610783894\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 495/1000 \t train loss 0.2848538024858995 \t val loss 1.3701130549112956\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 496/1000 \t train loss 0.2796948403120041 \t val loss 1.3649799426396687\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 497/1000 \t train loss 0.27582346580245276 \t val loss 1.3604787190755208\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 498/1000 \t train loss 0.273944689468904 \t val loss 1.3564979632695515\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 499/1000 \t train loss 0.270607091486454 \t val loss 1.3518006801605225\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 500/1000 \t train loss 0.2674940370700576 \t val loss 1.3525054057439168\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 501/1000 \t train loss 0.2672271965579553 \t val loss 1.3535401821136475\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 502/1000 \t train loss 0.26399169862270355 \t val loss 1.356910268465678\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 503/1000 \t train loss 0.26238091357729654 \t val loss 1.343839168548584\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 504/1000 \t train loss 0.26095767319202423 \t val loss 1.3512322902679443\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 505/1000 \t train loss 0.26124944537878036 \t val loss 1.354853590329488\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.69\n",
      "\n",
      " EPOCH 506/1000 \t train loss 0.2603802254254168 \t val loss 1.3467981815338135\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 507/1000 \t train loss 0.25959365476261487 \t val loss 1.3614853620529175\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 508/1000 \t train loss 0.25794774429364636 \t val loss 1.3481251398722331\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 509/1000 \t train loss 0.2568672875111753 \t val loss 1.3370100259780884\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 510/1000 \t train loss 0.2564554783430966 \t val loss 1.3408315976460774\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 511/1000 \t train loss 0.25537555326115 \t val loss 1.3536888758341472\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 512/1000 \t train loss 0.25523503802039404 \t val loss 1.3411449193954468\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.7\n",
      "\n",
      " EPOCH 513/1000 \t train loss 0.2552590749480508 \t val loss 1.336700439453125\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 514/1000 \t train loss 0.25323474407196045 \t val loss 1.3329426050186157\n",
      "train accuracy 0.9933110367892977 \t val accuracy 0.6966666666666667\n",
      "\n",
      " EPOCH 515/1000 \t train loss 0.25374466519464145 \t val loss 1.334535280863444\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 516/1000 \t train loss 0.25294349816712464 \t val loss 1.3337820370992024\n",
      "train accuracy 0.9936826458565589 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 517/1000 \t train loss 0.2574820918115703 \t val loss 1.3370668093363445\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 518/1000 \t train loss 0.2541566186330535 \t val loss 1.3403917948404949\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6933333333333334\n",
      "\n",
      " EPOCH 519/1000 \t train loss 0.2521839934316548 \t val loss 1.3297950824101765\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 520/1000 \t train loss 0.25209535455161874 \t val loss 1.323319395383199\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.7\n",
      "\n",
      " EPOCH 521/1000 \t train loss 0.2524042122743346 \t val loss 1.315913478533427\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6833333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 522/1000 \t train loss 0.2506601045077497 \t val loss 1.3258119424184163\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 523/1000 \t train loss 0.2528840181502429 \t val loss 1.3322745561599731\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 524/1000 \t train loss 0.25187743319706485 \t val loss 1.313873529434204\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 525/1000 \t train loss 0.25234639035029843 \t val loss 1.3211907148361206\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 526/1000 \t train loss 0.2517664540897716 \t val loss 1.30531644821167\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 527/1000 \t train loss 0.25130396065386856 \t val loss 1.324724555015564\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 528/1000 \t train loss 0.2513854882933877 \t val loss 1.3103607495625813\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 529/1000 \t train loss 0.2506994740529494 \t val loss 1.3023837407430012\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.69\n",
      "\n",
      " EPOCH 530/1000 \t train loss 0.251509276303378 \t val loss 1.3030380805333455\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.7033333333333334\n",
      "\n",
      " EPOCH 531/1000 \t train loss 0.2505163252353668 \t val loss 1.3358202775319417\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 532/1000 \t train loss 0.25224352153864776 \t val loss 1.3242167631785076\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.7066666666666667\n",
      "\n",
      " EPOCH 533/1000 \t train loss 0.2519720420241356 \t val loss 1.3076450824737549\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.7\n",
      "\n",
      " EPOCH 534/1000 \t train loss 0.2510467977686362 \t val loss 1.3471171855926514\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 535/1000 \t train loss 0.2506579201329838 \t val loss 1.3041166464487712\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 536/1000 \t train loss 0.25235600904984906 \t val loss 1.4541645844777424\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 537/1000 \t train loss 0.25645730712197046 \t val loss 1.4449435075124104\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 538/1000 \t train loss 0.2614838555455208 \t val loss 1.3946452140808105\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 539/1000 \t train loss 0.2673554379831661 \t val loss 1.697871446609497\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.5933333333333334\n",
      "\n",
      " EPOCH 540/1000 \t train loss 0.2933853336355903 \t val loss 1.540785272916158\n",
      "train accuracy 0.9855072463768116 \t val accuracy 0.6266666666666667\n",
      "\n",
      " EPOCH 541/1000 \t train loss 0.3371695496819236 \t val loss 1.6718213558197021\n",
      "train accuracy 0.9817911557041992 \t val accuracy 0.6133333333333333\n",
      "\n",
      " EPOCH 542/1000 \t train loss 0.32571260089224036 \t val loss 1.6163132588068645\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 543/1000 \t train loss 0.30630937218666077 \t val loss 1.4856146971384685\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 544/1000 \t train loss 0.2866216152906418 \t val loss 1.4100642204284668\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 545/1000 \t train loss 0.2744539122689854 \t val loss 1.3904152711232503\n",
      "train accuracy 0.9936826458565589 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 546/1000 \t train loss 0.2682973302223466 \t val loss 1.365080197652181\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 547/1000 \t train loss 0.2641208456321196 \t val loss 1.3492066065470378\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 548/1000 \t train loss 0.26052540269764984 \t val loss 1.3450825611750286\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 549/1000 \t train loss 0.25763562660325656 \t val loss 1.339987834294637\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 550/1000 \t train loss 0.25419187816706573 \t val loss 1.3363306522369385\n",
      "train accuracy 0.9929394277220365 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 551/1000 \t train loss 0.253130126405846 \t val loss 1.3330399592717488\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 552/1000 \t train loss 0.2512249526652423 \t val loss 1.3271974722544353\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 553/1000 \t train loss 0.25123420086773957 \t val loss 1.3228664795557659\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 554/1000 \t train loss 0.24922486733306537 \t val loss 1.3247047265370686\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 555/1000 \t train loss 0.24876369671388107 \t val loss 1.3159397443135579\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 556/1000 \t train loss 0.249015519564802 \t val loss 1.3201361497243245\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 557/1000 \t train loss 0.24887132373723117 \t val loss 1.309203823407491\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 558/1000 \t train loss 0.2479082332416014 \t val loss 1.3202455441157024\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 559/1000 \t train loss 0.2490280412814834 \t val loss 1.3163628975550334\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 560/1000 \t train loss 0.2467907958410003 \t val loss 1.318114161491394\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 561/1000 \t train loss 0.2473851117220792 \t val loss 1.3212312459945679\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 562/1000 \t train loss 0.2473416572267359 \t val loss 1.3106519381205242\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 563/1000 \t train loss 0.2460373491048813 \t val loss 1.29879625638326\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 564/1000 \t train loss 0.2473817379637198 \t val loss 1.2936091423034668\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 565/1000 \t train loss 0.24725658785213123 \t val loss 1.2956743240356445\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 566/1000 \t train loss 0.2453618340871551 \t val loss 1.3044517040252686\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 567/1000 \t train loss 0.24615443362431091 \t val loss 1.2939907312393188\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.7\n",
      "\n",
      " EPOCH 568/1000 \t train loss 0.2465363165194338 \t val loss 1.2967074712117512\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 569/1000 \t train loss 0.24573395062576642 \t val loss 1.2875847419102986\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 570/1000 \t train loss 0.24504724889993668 \t val loss 1.2825703223546345\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 571/1000 \t train loss 0.24670769816095178 \t val loss 1.3061281045277913\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 572/1000 \t train loss 0.24680991674011404 \t val loss 1.271741509437561\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 573/1000 \t train loss 0.24536929008635608 \t val loss 1.2770822048187256\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 574/1000 \t train loss 0.24906798926266757 \t val loss 1.2956079244613647\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 575/1000 \t train loss 0.24797701158306815 \t val loss 1.3336241642634075\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 576/1000 \t train loss 0.2465652579610998 \t val loss 1.279783805211385\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6966666666666667\n",
      "\n",
      " EPOCH 577/1000 \t train loss 0.24534016170284964 \t val loss 1.3018700281778972\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 578/1000 \t train loss 0.24577336690642618 \t val loss 1.2839306990305583\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 579/1000 \t train loss 0.24727480858564377 \t val loss 1.3146819273630779\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.68\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 580/1000 \t train loss 0.24718780476938595 \t val loss 1.3434523741404216\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 581/1000 \t train loss 0.2475469938733361 \t val loss 1.3354047536849976\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 582/1000 \t train loss 0.24988114156506278 \t val loss 1.322957197825114\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 583/1000 \t train loss 0.25237546319311316 \t val loss 1.343842585881551\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 584/1000 \t train loss 0.25165231322700327 \t val loss 1.4111261367797852\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 585/1000 \t train loss 0.25315821780399844 \t val loss 1.4704641898473103\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 586/1000 \t train loss 0.25545925308357587 \t val loss 1.342939058939616\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 587/1000 \t train loss 0.2534319446845488 \t val loss 1.3375636339187622\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 588/1000 \t train loss 0.24986860426989468 \t val loss 1.3164604902267456\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 589/1000 \t train loss 0.24403920701958917 \t val loss 1.2941022316614788\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 590/1000 \t train loss 0.24349564246156 \t val loss 1.2668836116790771\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 591/1000 \t train loss 0.24270795624364505 \t val loss 1.2787480751673381\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.69\n",
      "\n",
      " EPOCH 592/1000 \t train loss 0.24273197691548953 \t val loss 1.2820935249328613\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 593/1000 \t train loss 0.24308144097978418 \t val loss 1.3027849197387695\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 594/1000 \t train loss 0.24508703296834772 \t val loss 1.264577865600586\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 595/1000 \t train loss 0.24230688336220654 \t val loss 1.2696028153101604\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 596/1000 \t train loss 0.24176750670779834 \t val loss 1.2691632509231567\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 597/1000 \t train loss 0.24198607016693463 \t val loss 1.304279128710429\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 598/1000 \t train loss 0.2423329542983662 \t val loss 1.2921174764633179\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 599/1000 \t train loss 0.2448834404349327 \t val loss 1.2803430557250977\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 600/1000 \t train loss 0.24409048462455923 \t val loss 1.262792944908142\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 601/1000 \t train loss 0.2431921660900116 \t val loss 1.2900664806365967\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 602/1000 \t train loss 0.24435117705301804 \t val loss 1.3410845597585042\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 603/1000 \t train loss 0.24542127888311038 \t val loss 1.3544970353444417\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 604/1000 \t train loss 0.24761542271484027 \t val loss 1.3278565406799316\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 605/1000 \t train loss 0.2520479363473979 \t val loss 1.3865927457809448\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6233333333333333\n",
      "\n",
      " EPOCH 606/1000 \t train loss 0.25893405215306714 \t val loss 1.411996841430664\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6333333333333333\n",
      "\n",
      " EPOCH 607/1000 \t train loss 0.2721360332586549 \t val loss 1.3510918219884236\n",
      "train accuracy 0.9884801189149015 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 608/1000 \t train loss 0.2837354378266768 \t val loss 1.722870111465454\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6366666666666667\n",
      "\n",
      " EPOCH 609/1000 \t train loss 0.3113817125558853 \t val loss 1.5507744948069255\n",
      "train accuracy 0.9873652917131178 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 610/1000 \t train loss 0.3045224357735027 \t val loss 1.4310354391733806\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 611/1000 \t train loss 0.2815888510508971 \t val loss 1.3387568791707356\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 612/1000 \t train loss 0.26568327911875467 \t val loss 1.3181366125742595\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 613/1000 \t train loss 0.2562592253088951 \t val loss 1.2920928398768108\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 614/1000 \t train loss 0.2518039738590067 \t val loss 1.2827531496683757\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 615/1000 \t train loss 0.2479260272600434 \t val loss 1.2911034027735393\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 616/1000 \t train loss 0.24668950519778512 \t val loss 1.2826225360234578\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 617/1000 \t train loss 0.2458374168385159 \t val loss 1.2742928663889568\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 618/1000 \t train loss 0.24327251586047086 \t val loss 1.275954802831014\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 619/1000 \t train loss 0.24180532788688486 \t val loss 1.2623536984125774\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 620/1000 \t train loss 0.2437967068769715 \t val loss 1.2703049580256145\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 621/1000 \t train loss 0.2419616850939664 \t val loss 1.2898765007654827\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 622/1000 \t train loss 0.24110701815648514 \t val loss 1.2706817785898845\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 623/1000 \t train loss 0.24259962276978927 \t val loss 1.2723100185394287\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 624/1000 \t train loss 0.24190560525113886 \t val loss 1.2700937589009602\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 625/1000 \t train loss 0.24184948815540833 \t val loss 1.2870233058929443\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 626/1000 \t train loss 0.24123285575346512 \t val loss 1.3012932141621907\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 627/1000 \t train loss 0.24128835986961017 \t val loss 1.2724412282307942\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 628/1000 \t train loss 0.24103152006864548 \t val loss 1.2632228136062622\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 629/1000 \t train loss 0.24105673080140894 \t val loss 1.2743161519368489\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 630/1000 \t train loss 0.2423273419792002 \t val loss 1.3308257261912029\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 631/1000 \t train loss 0.2440851405262947 \t val loss 1.3578036228815715\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 632/1000 \t train loss 0.24542790922251614 \t val loss 1.268466631571452\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 633/1000 \t train loss 0.24520409852266312 \t val loss 1.3210839827855427\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 634/1000 \t train loss 0.24582830206914383 \t val loss 1.2815478245417278\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 635/1000 \t train loss 0.24665752188725906 \t val loss 1.4879104296366374\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6333333333333333\n",
      "\n",
      " EPOCH 636/1000 \t train loss 0.2551145397804 \t val loss 1.7907921473185222\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 637/1000 \t train loss 0.2888456786220724 \t val loss 1.975434422492981\n",
      "train accuracy 0.9847640282422891 \t val accuracy 0.6233333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 638/1000 \t train loss 0.3402169075879184 \t val loss 1.6969513893127441\n",
      "train accuracy 0.9858788554440728 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 639/1000 \t train loss 0.3253902359442277 \t val loss 1.5794233083724976\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 640/1000 \t train loss 0.2946390292861245 \t val loss 1.4452682336171467\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 641/1000 \t train loss 0.27708631686188956 \t val loss 1.3779231309890747\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6366666666666667\n",
      "\n",
      " EPOCH 642/1000 \t train loss 0.2649363645098426 \t val loss 1.340484857559204\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 643/1000 \t train loss 0.25801997970451007 \t val loss 1.31054691473643\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 644/1000 \t train loss 0.2534413540905172 \t val loss 1.3088874816894531\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 645/1000 \t train loss 0.2512074051932855 \t val loss 1.2952733437220256\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 646/1000 \t train loss 0.24735442752187903 \t val loss 1.2918730576833088\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 647/1000 \t train loss 0.2462122697721828 \t val loss 1.2937525510787964\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 648/1000 \t train loss 0.24491954730315643 \t val loss 1.289888858795166\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 649/1000 \t train loss 0.24402557923035187 \t val loss 1.2878313064575195\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 650/1000 \t train loss 0.24323145029219714 \t val loss 1.2903297742207844\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 651/1000 \t train loss 0.24323849109086124 \t val loss 1.288067102432251\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 652/1000 \t train loss 0.2432870106263594 \t val loss 1.2833159764607747\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 653/1000 \t train loss 0.24100380526347595 \t val loss 1.2837815682093303\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 654/1000 \t train loss 0.24215149879455566 \t val loss 1.2975468238194783\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 655/1000 \t train loss 0.24077659777619623 \t val loss 1.2973610560099285\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 656/1000 \t train loss 0.24016730284148996 \t val loss 1.3047668139139812\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 657/1000 \t train loss 0.239921282638203 \t val loss 1.29056982199351\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 658/1000 \t train loss 0.2412395802411166 \t val loss 1.2924846808115642\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 659/1000 \t train loss 0.2397844513708895 \t val loss 1.2928098837534587\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 660/1000 \t train loss 0.24032409218224612 \t val loss 1.2738145192464192\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 661/1000 \t train loss 0.24247224967588077 \t val loss 1.2712709506352742\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 662/1000 \t train loss 0.24227541278709064 \t val loss 1.280033270517985\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 663/1000 \t train loss 0.2418281456286257 \t val loss 1.306801438331604\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 664/1000 \t train loss 0.2420569732785225 \t val loss 1.2739146550496419\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.69\n",
      "\n",
      " EPOCH 665/1000 \t train loss 0.2416517219760201 \t val loss 1.279124101003011\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 666/1000 \t train loss 0.24168003621426495 \t val loss 1.2800883452097576\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 667/1000 \t train loss 0.2410392713817683 \t val loss 1.3298945426940918\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 668/1000 \t train loss 0.24146285924044522 \t val loss 1.2944097916285198\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 669/1000 \t train loss 0.24153429743918506 \t val loss 1.2917418479919434\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 670/1000 \t train loss 0.24288461966948074 \t val loss 1.2817139625549316\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 671/1000 \t train loss 0.24135697091167624 \t val loss 1.3529845476150513\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 672/1000 \t train loss 0.24339320036497983 \t val loss 1.3165095647176106\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 673/1000 \t train loss 0.24093293127688495 \t val loss 1.302641789118449\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 674/1000 \t train loss 0.243930576199835 \t val loss 1.2948175271352131\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.69\n",
      "\n",
      " EPOCH 675/1000 \t train loss 0.24425992708314548 \t val loss 1.3187395334243774\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 676/1000 \t train loss 0.24131180481477219 \t val loss 1.33327583471934\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 677/1000 \t train loss 0.242616745558652 \t val loss 1.291491429011027\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 678/1000 \t train loss 0.24113304777578873 \t val loss 1.330913503964742\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 679/1000 \t train loss 0.24216248840093613 \t val loss 1.2969617048899333\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 680/1000 \t train loss 0.242476340721954 \t val loss 1.3235177993774414\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 681/1000 \t train loss 0.24512048065662384 \t val loss 1.2804559071858723\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 682/1000 \t train loss 0.24330281195315448 \t val loss 1.283241868019104\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 683/1000 \t train loss 0.24180085279724814 \t val loss 1.26204518477122\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.7\n",
      "\n",
      " EPOCH 684/1000 \t train loss 0.2412289252335375 \t val loss 1.3111505111058552\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 685/1000 \t train loss 0.24388459866697138 \t val loss 1.3165881633758545\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 686/1000 \t train loss 0.2450538927858526 \t val loss 1.2967734336853027\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.69\n",
      "\n",
      " EPOCH 687/1000 \t train loss 0.24306941574270075 \t val loss 1.268797755241394\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 688/1000 \t train loss 0.2412423694675619 \t val loss 1.2921720345815022\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 689/1000 \t train loss 0.2430234896865758 \t val loss 1.33269206682841\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 690/1000 \t train loss 0.2412081096660007 \t val loss 1.2715033292770386\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6933333333333334\n",
      "\n",
      " EPOCH 691/1000 \t train loss 0.24068749289621005 \t val loss 1.2511219183603923\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 692/1000 \t train loss 0.23974443633447995 \t val loss 1.2704768975575764\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 693/1000 \t train loss 0.24051062085411765 \t val loss 1.3194520870844524\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 694/1000 \t train loss 0.24284583533352072 \t val loss 1.324306885401408\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 695/1000 \t train loss 0.24145108664577658 \t val loss 1.2640323241551716\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6633333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 696/1000 \t train loss 0.2402503781697967 \t val loss 1.3056689898173015\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 697/1000 \t train loss 0.24334739284081894 \t val loss 1.3120160897572835\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 698/1000 \t train loss 0.24235965582457455 \t val loss 1.3284902572631836\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 699/1000 \t train loss 0.2448734695261175 \t val loss 1.2516142924626668\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 700/1000 \t train loss 0.24284637787125327 \t val loss 1.2774558464686077\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 701/1000 \t train loss 0.2428522462194616 \t val loss 1.279967983563741\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 702/1000 \t train loss 0.24173200604590503 \t val loss 1.322633981704712\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 703/1000 \t train loss 0.24070233648473566 \t val loss 1.2872281471888225\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 704/1000 \t train loss 0.2403797906908122 \t val loss 1.282812515894572\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 705/1000 \t train loss 0.2411919500340115 \t val loss 1.2660526434580486\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.69\n",
      "\n",
      " EPOCH 706/1000 \t train loss 0.2437710944901813 \t val loss 1.2941070397694905\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 707/1000 \t train loss 0.24089094996452332 \t val loss 1.3808377186457317\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 708/1000 \t train loss 0.2468113438649611 \t val loss 1.300069014231364\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 709/1000 \t train loss 0.2484122941439802 \t val loss 1.3581633567810059\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 710/1000 \t train loss 0.25313778898932715 \t val loss 1.3640746275583904\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 711/1000 \t train loss 0.25796436179767956 \t val loss 1.3286724487940471\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 712/1000 \t train loss 0.2613272944634611 \t val loss 1.578403393427531\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6333333333333333\n",
      "\n",
      " EPOCH 713/1000 \t train loss 0.26150833612138574 \t val loss 1.318774660428365\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 714/1000 \t train loss 0.25246024334972555 \t val loss 1.2641797065734863\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 715/1000 \t train loss 0.24396866153586994 \t val loss 1.2786186933517456\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 716/1000 \t train loss 0.24155235561457547 \t val loss 1.275469183921814\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 717/1000 \t train loss 0.2411624240604314 \t val loss 1.275108019510905\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 718/1000 \t train loss 0.23862537741661072 \t val loss 1.2532118161519368\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.69\n",
      "\n",
      " EPOCH 719/1000 \t train loss 0.23883535916155035 \t val loss 1.2467469771703084\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 720/1000 \t train loss 0.23840640553019263 \t val loss 1.265027125676473\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 721/1000 \t train loss 0.2393518632108515 \t val loss 1.2864516576131184\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 722/1000 \t train loss 0.2381909963759509 \t val loss 1.2756298780441284\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 723/1000 \t train loss 0.23847401277585464 \t val loss 1.247598131497701\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 724/1000 \t train loss 0.23822085830298337 \t val loss 1.2741868893305461\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 725/1000 \t train loss 0.23888762295246124 \t val loss 1.2932902971903484\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 726/1000 \t train loss 0.23884424634955145 \t val loss 1.3142819007237752\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 727/1000 \t train loss 0.24315790086984634 \t val loss 1.2638057072957356\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 728/1000 \t train loss 0.2403446605259722 \t val loss 1.2786988814671834\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.69\n",
      "\n",
      " EPOCH 729/1000 \t train loss 0.24096572737802158 \t val loss 1.2827779452006023\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 730/1000 \t train loss 0.2403653460470113 \t val loss 1.3463984330495198\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 731/1000 \t train loss 0.2415658411654559 \t val loss 1.3320396343866985\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 732/1000 \t train loss 0.2425989183512601 \t val loss 1.2695891459782918\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 733/1000 \t train loss 0.24244683506813916 \t val loss 1.3299628496170044\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6333333333333333\n",
      "\n",
      " EPOCH 734/1000 \t train loss 0.2448366548527371 \t val loss 1.326076825459798\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 735/1000 \t train loss 0.2464125698262995 \t val loss 1.416200876235962\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 736/1000 \t train loss 0.24858189712871204 \t val loss 1.3816982905069988\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 737/1000 \t train loss 0.2511530843648044 \t val loss 1.2850522597630818\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 738/1000 \t train loss 0.2496074749664827 \t val loss 1.39865775903066\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 739/1000 \t train loss 0.25226634402166714 \t val loss 1.3781994978586833\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 740/1000 \t train loss 0.24741306630047885 \t val loss 1.300986647605896\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 741/1000 \t train loss 0.24496588043191217 \t val loss 1.2414494355519612\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 742/1000 \t train loss 0.24205456538633865 \t val loss 1.2549709876378377\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 743/1000 \t train loss 0.2384454614736817 \t val loss 1.2741262118021648\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 744/1000 \t train loss 0.23693433539433914 \t val loss 1.2510095834732056\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 745/1000 \t train loss 0.23704379119656302 \t val loss 1.2401549816131592\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 746/1000 \t train loss 0.23752556944435294 \t val loss 1.2627816597620647\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 747/1000 \t train loss 0.2376877015287226 \t val loss 1.2877583901087444\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 748/1000 \t train loss 0.2373752546581355 \t val loss 1.2893924713134766\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 749/1000 \t train loss 0.23747827248139816 \t val loss 1.2574610312779744\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 750/1000 \t train loss 0.23963797769763254 \t val loss 1.2562556266784668\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 751/1000 \t train loss 0.238410008224574 \t val loss 1.2704466581344604\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.69\n",
      "\n",
      " EPOCH 752/1000 \t train loss 0.23952322791923175 \t val loss 1.3082918723424275\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.66\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 753/1000 \t train loss 0.24108755114403638 \t val loss 1.3135398626327515\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 754/1000 \t train loss 0.24300347878174347 \t val loss 1.2668671210606892\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 755/1000 \t train loss 0.24361763284964996 \t val loss 1.3079564571380615\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 756/1000 \t train loss 0.24519228325648743 \t val loss 1.2940231164296467\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 757/1000 \t train loss 0.2463948835026134 \t val loss 1.4232908884684246\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6233333333333333\n",
      "\n",
      " EPOCH 758/1000 \t train loss 0.24985074387355286 \t val loss 1.3856410185496013\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 759/1000 \t train loss 0.25255879082463006 \t val loss 1.3719706137975056\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 760/1000 \t train loss 0.25299188833345065 \t val loss 1.3320951859156291\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 761/1000 \t train loss 0.2521154975349253 \t val loss 1.330613613128662\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 762/1000 \t train loss 0.2492723749442534 \t val loss 1.4181878566741943\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 763/1000 \t train loss 0.24750932238318704 \t val loss 1.3516005674997966\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 764/1000 \t train loss 0.24506563490087335 \t val loss 1.2531002362569172\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 765/1000 \t train loss 0.2462882616303184 \t val loss 1.2552922169367473\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 766/1000 \t train loss 0.24320687489076095 \t val loss 1.2725743452707927\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 767/1000 \t train loss 0.24139089272780853 \t val loss 1.289113203684489\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 768/1000 \t train loss 0.24040767144073139 \t val loss 1.2406188646952312\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 769/1000 \t train loss 0.23829295215281573 \t val loss 1.2576673030853271\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 770/1000 \t train loss 0.23945542086254468 \t val loss 1.2582956949869792\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 771/1000 \t train loss 0.23907959867607464 \t val loss 1.2889785369237263\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 772/1000 \t train loss 0.23844628577882593 \t val loss 1.2505745490392048\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 773/1000 \t train loss 0.2383201914754781 \t val loss 1.2532171805699666\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 774/1000 \t train loss 0.2380735779350454 \t val loss 1.2615764141082764\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 775/1000 \t train loss 0.2366325320167975 \t val loss 1.30255393187205\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.63\n",
      "\n",
      " EPOCH 776/1000 \t train loss 0.2389509298584678 \t val loss 1.294328014055888\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 777/1000 \t train loss 0.2375209094448523 \t val loss 1.2769206762313843\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 778/1000 \t train loss 0.24017852273854343 \t val loss 1.294859250386556\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 779/1000 \t train loss 0.2402564917098392 \t val loss 1.3206310272216797\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 780/1000 \t train loss 0.2410622855479067 \t val loss 1.3122642834981282\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 781/1000 \t train loss 0.24150252816351978 \t val loss 1.3678885698318481\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 782/1000 \t train loss 0.24347401681271466 \t val loss 1.3092133204142253\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 783/1000 \t train loss 0.24534719437360764 \t val loss 1.4008745749791462\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 784/1000 \t train loss 0.24842153218659488 \t val loss 1.333666443824768\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 785/1000 \t train loss 0.24730033698407086 \t val loss 1.3930025100708008\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 786/1000 \t train loss 0.25192018327387894 \t val loss 1.4501789410909016\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 787/1000 \t train loss 0.2519909847866405 \t val loss 1.3546827634175618\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 788/1000 \t train loss 0.24721062115647577 \t val loss 1.3221468130747478\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 789/1000 \t train loss 0.2432445457035845 \t val loss 1.2938350041707356\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 790/1000 \t train loss 0.24193880571560425 \t val loss 1.261953592300415\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 791/1000 \t train loss 0.24118591167710043 \t val loss 1.320728023846944\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 792/1000 \t train loss 0.2399421984499151 \t val loss 1.3157926400502522\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 793/1000 \t train loss 0.23948340862989426 \t val loss 1.259532888730367\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 794/1000 \t train loss 0.2386821217157624 \t val loss 1.2654204765955608\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 795/1000 \t train loss 0.23963650180534882 \t val loss 1.293683131535848\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 796/1000 \t train loss 0.23863638124682687 \t val loss 1.3346761067708333\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 797/1000 \t train loss 0.24204087934710763 \t val loss 1.3067053159077961\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 798/1000 \t train loss 0.24127659811214966 \t val loss 1.3141441345214844\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 799/1000 \t train loss 0.24283521486954254 \t val loss 1.293857455253601\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 800/1000 \t train loss 0.24385305426337503 \t val loss 1.3653558095296223\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 801/1000 \t train loss 0.24400805817408996 \t val loss 1.4277105728785198\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6266666666666667\n",
      "\n",
      " EPOCH 802/1000 \t train loss 0.24856536835432053 \t val loss 1.3278741836547852\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6933333333333334\n",
      "\n",
      " EPOCH 803/1000 \t train loss 0.2495853067799048 \t val loss 1.41492756207784\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 804/1000 \t train loss 0.25340783257376065 \t val loss 1.3661823670069377\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6366666666666667\n",
      "\n",
      " EPOCH 805/1000 \t train loss 0.25366690348495136 \t val loss 1.4235862890879314\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 806/1000 \t train loss 0.2509802254763516 \t val loss 1.2979390223821003\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 807/1000 \t train loss 0.24323743243109097 \t val loss 1.2686320940653484\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 808/1000 \t train loss 0.24076848951253024 \t val loss 1.2781723737716675\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 809/1000 \t train loss 0.23849193345416675 \t val loss 1.2821402152379353\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6733333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 810/1000 \t train loss 0.2368424954739484 \t val loss 1.2650150855382283\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 811/1000 \t train loss 0.2367385761304335 \t val loss 1.251135031382243\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 812/1000 \t train loss 0.23601466891440478 \t val loss 1.2626876433690388\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 813/1000 \t train loss 0.23669501732696185 \t val loss 1.2786585887273152\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 814/1000 \t train loss 0.2371108125556599 \t val loss 1.269577145576477\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 815/1000 \t train loss 0.2375701300122521 \t val loss 1.257632573445638\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 816/1000 \t train loss 0.23740026354789734 \t val loss 1.2621002197265625\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 817/1000 \t train loss 0.23786795410242947 \t val loss 1.2616522312164307\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 818/1000 \t train loss 0.23733012920076196 \t val loss 1.2897980610529582\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 819/1000 \t train loss 0.2376979332078587 \t val loss 1.291806936264038\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 820/1000 \t train loss 0.2376097792928869 \t val loss 1.2699908812840779\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 821/1000 \t train loss 0.23880266533656555 \t val loss 1.2972955306371052\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 822/1000 \t train loss 0.24141313880681992 \t val loss 1.3111903270085652\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 823/1000 \t train loss 0.24248491498557004 \t val loss 1.3783520062764485\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 824/1000 \t train loss 0.24441299181092868 \t val loss 1.5456171035766602\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.63\n",
      "\n",
      " EPOCH 825/1000 \t train loss 0.252623703669418 \t val loss 1.4541853268941243\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 826/1000 \t train loss 0.25878905166279187 \t val loss 1.406467040379842\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 827/1000 \t train loss 0.2660178311846473 \t val loss 1.57596222559611\n",
      "train accuracy 0.9884801189149015 \t val accuracy 0.6266666666666667\n",
      "\n",
      " EPOCH 828/1000 \t train loss 0.27516966042193497 \t val loss 1.4143441518147786\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 829/1000 \t train loss 0.2803071005777879 \t val loss 1.6074949900309246\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.63\n",
      "\n",
      " EPOCH 830/1000 \t train loss 0.279245873066512 \t val loss 1.4748607476552327\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 831/1000 \t train loss 0.2674049281261184 \t val loss 1.3272013266881306\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 832/1000 \t train loss 0.2540678503838452 \t val loss 1.2942813237508137\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.63\n",
      "\n",
      " EPOCH 833/1000 \t train loss 0.2469520311463963 \t val loss 1.2683216333389282\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 834/1000 \t train loss 0.24198369139974768 \t val loss 1.2606679201126099\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 835/1000 \t train loss 0.23967830769040369 \t val loss 1.2654885450998943\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 836/1000 \t train loss 0.23790173774415796 \t val loss 1.2630925178527832\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 837/1000 \t train loss 0.23848161710934204 \t val loss 1.2540210088094075\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 838/1000 \t train loss 0.2368687472560189 \t val loss 1.251275102297465\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 839/1000 \t train loss 0.23765085434371774 \t val loss 1.2529383500417073\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 840/1000 \t train loss 0.23738657479936426 \t val loss 1.2531971136728923\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 841/1000 \t train loss 0.23687541552565314 \t val loss 1.2653774817784627\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 842/1000 \t train loss 0.2367478453300216 \t val loss 1.2660021781921387\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 843/1000 \t train loss 0.23590062084523114 \t val loss 1.2542985280354817\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 844/1000 \t train loss 0.23651046576825055 \t val loss 1.2447781562805176\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6966666666666667\n",
      "\n",
      " EPOCH 845/1000 \t train loss 0.23595917292616583 \t val loss 1.2773879369099934\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 846/1000 \t train loss 0.23717316104607147 \t val loss 1.2755787372589111\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 847/1000 \t train loss 0.2368659566749226 \t val loss 1.2418909470240276\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 848/1000 \t train loss 0.2360680252313614 \t val loss 1.2548023064931233\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 849/1000 \t train loss 0.23523772982033817 \t val loss 1.2572101751963298\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 850/1000 \t train loss 0.23904696513306012 \t val loss 1.2829915285110474\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 851/1000 \t train loss 0.2386766184460033 \t val loss 1.2768681049346924\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 852/1000 \t train loss 0.2377476543188095 \t val loss 1.2767754793167114\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 853/1000 \t train loss 0.23691879890181802 \t val loss 1.2789249420166016\n",
      "train accuracy 0.9925678186547752 \t val accuracy 0.69\n",
      "\n",
      " EPOCH 854/1000 \t train loss 0.23907292905178937 \t val loss 1.3000119924545288\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 855/1000 \t train loss 0.24031836674972015 \t val loss 1.4279311895370483\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.63\n",
      "\n",
      " EPOCH 856/1000 \t train loss 0.24477493559772318 \t val loss 1.3247154553731282\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 857/1000 \t train loss 0.2453409812667153 \t val loss 1.3614776134490967\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 858/1000 \t train loss 0.2518541779030453 \t val loss 1.4017396370569866\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 859/1000 \t train loss 0.2693310793150555 \t val loss 1.3630084991455078\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 860/1000 \t train loss 0.28072458099235187 \t val loss 1.408040444056193\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 861/1000 \t train loss 0.2694599608128721 \t val loss 1.37296724319458\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 862/1000 \t train loss 0.25765871730717743 \t val loss 1.3161341349283855\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 863/1000 \t train loss 0.2464019696820866 \t val loss 1.2922385136286418\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 864/1000 \t train loss 0.24275481700897217 \t val loss 1.2827555338541667\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 865/1000 \t train loss 0.23955905369736932 \t val loss 1.2763388951619465\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 866/1000 \t train loss 0.23923131349411877 \t val loss 1.2732788721720378\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 867/1000 \t train loss 0.23887881365689365 \t val loss 1.275549093882243\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 868/1000 \t train loss 0.2384811450134624 \t val loss 1.2732512950897217\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 869/1000 \t train loss 0.236133221198212 \t val loss 1.2590258916219075\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 870/1000 \t train loss 0.2377174828540195 \t val loss 1.2728485266367595\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 871/1000 \t train loss 0.23636495592919263 \t val loss 1.2613280216852825\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 872/1000 \t train loss 0.23645647479729218 \t val loss 1.248517672220866\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 873/1000 \t train loss 0.2369372235103087 \t val loss 1.2551679611206055\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 874/1000 \t train loss 0.23775718767534604 \t val loss 1.2641024192174275\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 875/1000 \t train loss 0.23784274946559558 \t val loss 1.2746470769246419\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 876/1000 \t train loss 0.23698273504322226 \t val loss 1.2425055503845215\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.69\n",
      "\n",
      " EPOCH 877/1000 \t train loss 0.23574614186178555 \t val loss 1.2452147801717122\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 878/1000 \t train loss 0.23679058321497656 \t val loss 1.2730875809987385\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 879/1000 \t train loss 0.237808418544856 \t val loss 1.273266037305196\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 880/1000 \t train loss 0.23740116574547507 \t val loss 1.2718424797058105\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 881/1000 \t train loss 0.2381880682977763 \t val loss 1.2672043244043987\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 882/1000 \t train loss 0.23861115967685526 \t val loss 1.2763432661692302\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 883/1000 \t train loss 0.24001117118380286 \t val loss 1.30141015847524\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 884/1000 \t train loss 0.2415408187291839 \t val loss 1.3624115784962971\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 885/1000 \t train loss 0.24349984458901666 \t val loss 1.4014903704325359\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 886/1000 \t train loss 0.24621851268139752 \t val loss 1.2921075820922852\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 887/1000 \t train loss 0.24842246215451846 \t val loss 1.3702181577682495\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 888/1000 \t train loss 0.25267012823711743 \t val loss 1.3214910825093586\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 889/1000 \t train loss 0.2544665187597275 \t val loss 1.4288359880447388\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 890/1000 \t train loss 0.2579506703398444 \t val loss 1.4130517641703289\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 891/1000 \t train loss 0.2575217316096479 \t val loss 1.3500421444574993\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 892/1000 \t train loss 0.2518976615233855 \t val loss 1.3080908457438152\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 893/1000 \t train loss 0.24297548695044083 \t val loss 1.2771084308624268\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 894/1000 \t train loss 0.24059466949918054 \t val loss 1.251894434293111\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 895/1000 \t train loss 0.23774669116193597 \t val loss 1.2483408451080322\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 896/1000 \t train loss 0.2384527332403443 \t val loss 1.2705921332041423\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 897/1000 \t train loss 0.2363350885835561 \t val loss 1.2792883316675823\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 898/1000 \t train loss 0.23685328459197824 \t val loss 1.2503999869028728\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 899/1000 \t train loss 0.23627760058099573 \t val loss 1.247248927752177\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 900/1000 \t train loss 0.23630768263881857 \t val loss 1.2494789759318035\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 901/1000 \t train loss 0.2387434576045383 \t val loss 1.2736034790674846\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 902/1000 \t train loss 0.23782902481881055 \t val loss 1.286585847536723\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 903/1000 \t train loss 0.23767909814010968 \t val loss 1.2608365217844646\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 904/1000 \t train loss 0.23742401870814236 \t val loss 1.2588969071706135\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 905/1000 \t train loss 0.2381335117600181 \t val loss 1.264185110727946\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 906/1000 \t train loss 0.23909613286907022 \t val loss 1.325762112935384\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 907/1000 \t train loss 0.2392850172790614 \t val loss 1.3183292150497437\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 908/1000 \t train loss 0.24148706075820056 \t val loss 1.2873962720235188\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 909/1000 \t train loss 0.24167834628712048 \t val loss 1.3157548507054646\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 910/1000 \t train loss 0.24602405523711984 \t val loss 1.2822903792063396\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 911/1000 \t train loss 0.24926204573024402 \t val loss 1.5931384166081746\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6166666666666667\n",
      "\n",
      " EPOCH 912/1000 \t train loss 0.2652816880833019 \t val loss 1.6812626123428345\n",
      "train accuracy 0.9869936826458565 \t val accuracy 0.6266666666666667\n",
      "\n",
      " EPOCH 913/1000 \t train loss 0.2839754725044424 \t val loss 1.465532620747884\n",
      "train accuracy 0.9884801189149015 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 914/1000 \t train loss 0.27682185579429974 \t val loss 1.384049892425537\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 915/1000 \t train loss 0.25976697355508804 \t val loss 1.3109369277954102\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 916/1000 \t train loss 0.24883779951117255 \t val loss 1.282924771308899\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 917/1000 \t train loss 0.2444190647114407 \t val loss 1.2833142280578613\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 918/1000 \t train loss 0.24162776971405203 \t val loss 1.2741454044977825\n",
      "train accuracy 0.9884801189149015 \t val accuracy 0.6966666666666667\n",
      "\n",
      " EPOCH 919/1000 \t train loss 0.23887142674489456 \t val loss 1.2721812725067139\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 920/1000 \t train loss 0.2389317899942398 \t val loss 1.2663867870966594\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 921/1000 \t train loss 0.23837830397215756 \t val loss 1.2638719479242961\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 922/1000 \t train loss 0.23923688517375427 \t val loss 1.2516638040542603\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 923/1000 \t train loss 0.23637128553607248 \t val loss 1.2510485649108887\n",
      "train accuracy 0.992196209587514 \t val accuracy 0.69\n",
      "\n",
      " EPOCH 924/1000 \t train loss 0.23779313943602823 \t val loss 1.2473189036051433\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 925/1000 \t train loss 0.23716594549742612 \t val loss 1.2751856247584026\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 926/1000 \t train loss 0.23773082345724106 \t val loss 1.2638928890228271\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 927/1000 \t train loss 0.23846853321248834 \t val loss 1.264002760251363\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 928/1000 \t train loss 0.23808849128809842 \t val loss 1.2421950896581013\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 929/1000 \t train loss 0.23786399242552844 \t val loss 1.3021717071533203\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6333333333333333\n",
      "\n",
      " EPOCH 930/1000 \t train loss 0.23844305900010196 \t val loss 1.2707455158233643\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 931/1000 \t train loss 0.23864897205071015 \t val loss 1.2523057063420613\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 932/1000 \t train loss 0.2392644868655638 \t val loss 1.2560594479242961\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 933/1000 \t train loss 0.23936948044733566 \t val loss 1.2896284659703572\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 934/1000 \t train loss 0.24001273377375168 \t val loss 1.3043231169382732\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 935/1000 \t train loss 0.23910507153381 \t val loss 1.2600382566452026\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 936/1000 \t train loss 0.2373599112033844 \t val loss 1.2442950805028279\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 937/1000 \t train loss 0.23787177421829916 \t val loss 1.290440599123637\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 938/1000 \t train loss 0.2376341542059725 \t val loss 1.3024506568908691\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 939/1000 \t train loss 0.2391849857839671 \t val loss 1.2802844842274983\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 940/1000 \t train loss 0.23873491449789566 \t val loss 1.258363167444865\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 941/1000 \t train loss 0.24075298349965701 \t val loss 1.2724385261535645\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 942/1000 \t train loss 0.23937881670214914 \t val loss 1.3290589253107707\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.65\n",
      "\n",
      " EPOCH 943/1000 \t train loss 0.24168442054228348 \t val loss 1.2644588549931843\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 944/1000 \t train loss 0.24164684116840363 \t val loss 1.2568570375442505\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 945/1000 \t train loss 0.23997790840539066 \t val loss 1.2651909589767456\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 946/1000 \t train loss 0.2389500547539104 \t val loss 1.3262756665547688\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.62\n",
      "\n",
      " EPOCH 947/1000 \t train loss 0.24133457446640189 \t val loss 1.2758462031682332\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 948/1000 \t train loss 0.23945704034783624 \t val loss 1.2904024521509807\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 949/1000 \t train loss 0.2415853257883679 \t val loss 1.2659866015116374\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 950/1000 \t train loss 0.2391262948513031 \t val loss 1.2961156765619914\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6466666666666666\n",
      "\n",
      " EPOCH 951/1000 \t train loss 0.23849719017744064 \t val loss 1.2580024401346843\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 952/1000 \t train loss 0.23983531512997366 \t val loss 1.2611878315607707\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 953/1000 \t train loss 0.23945799469947815 \t val loss 1.2698551813761394\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 954/1000 \t train loss 0.23873316496610641 \t val loss 1.3148141304651897\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.64\n",
      "\n",
      " EPOCH 955/1000 \t train loss 0.23968413878570904 \t val loss 1.2846406698226929\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 956/1000 \t train loss 0.23891077800230545 \t val loss 1.2745620012283325\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 957/1000 \t train loss 0.239938154139302 \t val loss 1.2689933776855469\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 958/1000 \t train loss 0.23886568708853287 \t val loss 1.318140705426534\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 959/1000 \t train loss 0.2400392083959146 \t val loss 1.311350425084432\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 960/1000 \t train loss 0.2407846748828888 \t val loss 1.333884874979655\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 961/1000 \t train loss 0.24043809419328516 \t val loss 1.2544058958689372\n",
      "train accuracy 0.9884801189149015 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 962/1000 \t train loss 0.239088427614082 \t val loss 1.2983553012212117\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 963/1000 \t train loss 0.24111033976078033 \t val loss 1.2894069353739421\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 964/1000 \t train loss 0.24006101963194934 \t val loss 1.3144930203755696\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 965/1000 \t train loss 0.2429201982238076 \t val loss 1.2791950702667236\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 966/1000 \t train loss 0.24263545057990335 \t val loss 1.2847607930501301\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 967/1000 \t train loss 0.24219860949299551 \t val loss 1.3035367727279663\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6866666666666666\n",
      "\n",
      " EPOCH 968/1000 \t train loss 0.2414717200127515 \t val loss 1.311673363049825\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 969/1000 \t train loss 0.24116413430734115 \t val loss 1.3059174219767253\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.62\n",
      "\n",
      " EPOCH 970/1000 \t train loss 0.2401522235436873 \t val loss 1.260385513305664\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 971/1000 \t train loss 0.24027727408842606 \t val loss 1.2922344207763672\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 972/1000 \t train loss 0.23944128643382678 \t val loss 1.2889292240142822\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 973/1000 \t train loss 0.23894229937683453 \t val loss 1.2921406825383503\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6366666666666667\n",
      "\n",
      " EPOCH 974/1000 \t train loss 0.23959520933302966 \t val loss 1.245782732963562\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 975/1000 \t train loss 0.23799193040891128 \t val loss 1.2685542901357014\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.68\n",
      "\n",
      " EPOCH 976/1000 \t train loss 0.2379308430985971 \t val loss 1.275994062423706\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 977/1000 \t train loss 0.23928376490419562 \t val loss 1.2959872086842854\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6366666666666667\n",
      "\n",
      " EPOCH 978/1000 \t train loss 0.23797066103328357 \t val loss 1.26685631275177\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 979/1000 \t train loss 0.23875363238833167 \t val loss 1.2797598838806152\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 980/1000 \t train loss 0.2384847714142366 \t val loss 1.2822435299555461\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 981/1000 \t train loss 0.23998075520450418 \t val loss 1.3059491316477458\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6366666666666667\n",
      "\n",
      " EPOCH 982/1000 \t train loss 0.2418540661985224 \t val loss 1.3364496231079102\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6333333333333333\n",
      "\n",
      " EPOCH 983/1000 \t train loss 0.24268722601912238 \t val loss 1.3362044493357341\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6733333333333333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " EPOCH 984/1000 \t train loss 0.24288096075708215 \t val loss 1.2967102527618408\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6733333333333333\n",
      "\n",
      " EPOCH 985/1000 \t train loss 0.24152995578267358 \t val loss 1.2933202187220256\n",
      "train accuracy 0.9918246005202527 \t val accuracy 0.6366666666666667\n",
      "\n",
      " EPOCH 986/1000 \t train loss 0.24195785278623755 \t val loss 1.3119450410207112\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.6433333333333333\n",
      "\n",
      " EPOCH 987/1000 \t train loss 0.2406262762167237 \t val loss 1.3440572420756023\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6633333333333333\n",
      "\n",
      " EPOCH 988/1000 \t train loss 0.24060325866395776 \t val loss 1.2808152039845784\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.69\n",
      "\n",
      " EPOCH 989/1000 \t train loss 0.23977402394468134 \t val loss 1.2917913993199666\n",
      "train accuracy 0.9895949461166852 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 990/1000 \t train loss 0.24138785830952905 \t val loss 1.3089802662531536\n",
      "train accuracy 0.9888517279821628 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 991/1000 \t train loss 0.24194048683751712 \t val loss 1.319309115409851\n",
      "train accuracy 0.9910813823857302 \t val accuracy 0.6766666666666666\n",
      "\n",
      " EPOCH 992/1000 \t train loss 0.24756725132465363 \t val loss 1.4415157636006672\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 993/1000 \t train loss 0.247427951883186 \t val loss 1.3877593676249187\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6533333333333333\n",
      "\n",
      " EPOCH 994/1000 \t train loss 0.2465462853962725 \t val loss 1.3094079891840618\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 995/1000 \t train loss 0.2447671118107709 \t val loss 1.2724241813023884\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.67\n",
      "\n",
      " EPOCH 996/1000 \t train loss 0.24145508083430203 \t val loss 1.2804428339004517\n",
      "train accuracy 0.9914529914529915 \t val accuracy 0.6566666666666666\n",
      "\n",
      " EPOCH 997/1000 \t train loss 0.24075551466508346 \t val loss 1.327353874842326\n",
      "train accuracy 0.9899665551839465 \t val accuracy 0.66\n",
      "\n",
      " EPOCH 998/1000 \t train loss 0.23872551863843744 \t val loss 1.2523090442021687\n",
      "train accuracy 0.990709773318469 \t val accuracy 0.6833333333333333\n",
      "\n",
      " EPOCH 999/1000 \t train loss 0.23922523652965372 \t val loss 1.2646971146265666\n",
      "train accuracy 0.9903381642512077 \t val accuracy 0.6666666666666666\n",
      "\n",
      " EPOCH 1000/1000 \t train loss 0.24105454304001547 \t val loss 1.243255376815796\n",
      "train accuracy 0.989223337049424 \t val accuracy 0.6766666666666666\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "cut_length = 500\n",
    "data_train, data_test, train_loader, test_loader, word2index = generate_data_loader(df_data, batch_size, cut_length)\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Parameters:\n",
    "    # Preprocessing parameeters\n",
    "    seq_len: int = cut_length\n",
    "    num_words: int = len(word2index)\n",
    "\n",
    "    # Model parameters\n",
    "    embedding_size: int = 100\n",
    "    out_size: int = 64\n",
    "    stride: int = 2\n",
    "    class_num: int = len(le.classes_)\n",
    "    dense_out: int =128\n",
    "        \n",
    "param = Parameters\n",
    "lr = 0.001\n",
    "num_epochs = 1000\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = TextCNN(param).to(device)\n",
    "print(model)\n",
    "criterion = nn.NLLLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr,weight_decay=1e-8)\n",
    "\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\n",
    "    # train\n",
    "    train_epoch_loss = 0\n",
    "    # set net to train mode\n",
    "    model.train()\n",
    "    train_preds = []\n",
    "    \n",
    "    for X_train, y_train in train_loader:\n",
    "        X_train, y_train = X_train.to(device), y_train.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        # pass the data into the network and store the output \n",
    "        y_train_pred = model(X_train)\n",
    "        # Calculate the loss between the output and target \n",
    "        train_loss = criterion(y_train_pred, y_train)\n",
    "\n",
    "        # Perform backpropagation \n",
    "        l2_lambda = 0.01\n",
    "        l2_reg = torch.tensor(0.).to(device)\n",
    "        for param in model.parameters():\n",
    "            l2_reg += torch.norm(param)\n",
    "        train_loss += l2_lambda * l2_reg\n",
    "        \n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Add the loss \n",
    "        train_epoch_loss +=  train_loss.item() \n",
    "        \n",
    "        # Prediction\n",
    "        train_preds += list(torch.argmax(y_train_pred, dim=1).cpu().detach().numpy())\n",
    "        \n",
    "    # validation \n",
    "    with torch.no_grad():\n",
    "        val_preds = []\n",
    "        val_epoch_loss = 0\n",
    "        model.eval()\n",
    "        for X_val, y_val in test_loader:\n",
    "            X_val, y_val = X_val.to(device), y_val.to(device)\n",
    "            y_val_pred = model(X_val)\n",
    "\n",
    "            val_loss = criterion(y_val_pred, y_val)\n",
    "            l2_lambda = 0.01\n",
    "            l2_reg = torch.tensor(0.).to(device)\n",
    "            for param in model.parameters():\n",
    "                l2_reg += torch.norm(param)\n",
    "            val_loss += l2_lambda * l2_reg\n",
    "            val_epoch_loss +=  val_loss.item() \n",
    "            val_preds += list(torch.argmax(y_val_pred, dim=1).cpu().detach().numpy())\n",
    "            \n",
    "    # append average epoch loss to losses list  \n",
    "    train_losses.append(train_epoch_loss/len(train_loader))\n",
    "    val_losses.append(val_epoch_loss/len(test_loader)) \n",
    "    print('\\n EPOCH {}/{} \\t train loss {} \\t val loss {}'\\\n",
    "      .format(epoch + 1, num_epochs,train_losses[-1],val_losses[-1]))\n",
    "    print('train accuracy {} \\t val accuracy {}'\\\n",
    "      .format(accuracy_score(data_train['class'], train_preds), \n",
    "              accuracy_score(data_test['class'], val_preds)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "79867de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x648 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_loss(train_losses, val_losses):\n",
    "    \"\"\"\n",
    "    You may end up plotting the training loss and validation loss multiple times\n",
    "    It is better to implement a plot function instead of rewriting the plotting steps\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (12,9))\n",
    "    plt.plot(range(1,len(train_losses)+1), train_losses)\n",
    "    plt.plot(range(1,len(val_losses)+1), val_losses, color='orange')\n",
    "    plt.legend(['Train Loss','Validation Loss'], loc='upper right')\n",
    "    plt.xlabel('Number of epochs',fontsize=14)\n",
    "    plt.ylabel('Average loss',fontsize=14)\n",
    "    plt.title(\"Average loss over epochs\",fontsize=16)\n",
    "    plt.show()\n",
    "plot_loss(train_losses, val_losses)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e4a04f6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.66      0.65        50\n",
      "           1       0.86      0.64      0.74        50\n",
      "           2       0.61      0.74      0.67        50\n",
      "           3       0.62      0.68      0.65        50\n",
      "           4       0.76      0.82      0.79        50\n",
      "           5       0.63      0.52      0.57        50\n",
      "\n",
      "    accuracy                           0.68       300\n",
      "   macro avg       0.69      0.68      0.68       300\n",
      "weighted avg       0.69      0.68      0.68       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(data_test['class'], val_preds))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
